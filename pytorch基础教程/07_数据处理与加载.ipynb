{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch数据处理与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，处理和加载数据是深度学习训练过程中的关键步骤。\n",
    "\n",
    "为了高效地处理数据，PyTorch 提供了强大的工具，包括 torch.utils.data.Dataset 和 torch.utils.data.DataLoader，帮助我们管理数据集、批量加载和数据增强等任务。\n",
    "\n",
    "PyTorch 数据处理与加载的介绍：\n",
    "\n",
    "- 自定义 Dataset：通过继承 torch.utils.data.Dataset 来加载自己的数据集。\n",
    "\n",
    "- DataLoader：DataLoader 按批次加载数据，支持多线程加载并进行数据打乱。\n",
    "\n",
    "- 数据预处理与增强：使用 torchvision.transforms 进行常见的图像预处理和增强操作，提高模型的泛化能力。\n",
    "\n",
    "- 加载标准数据集：torchvision.datasets 提供了许多常见的数据集，简化了数据加载过程。\n",
    "\n",
    "- 多个数据源：通过组合多个 Dataset 实例来处理来自不同来源的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义 Dataset\n",
    "\n",
    "torch.utils.data.Dataset 是一个抽象类，允许你从自己的数据源中创建数据集。\n",
    "\n",
    "我们需要继承该类并实现以下两个方法：\n",
    "\n",
    "- \\_\\_len__(self)：返回数据集中的样本数量。\n",
    "\n",
    "- \\_\\_getitem__(self, idx)：通过索引返回一个样本。\n",
    "\n",
    "假设我们有一个简单的 CSV 文件或一些列表数据，我们可以通过继承 Dataset 类来创建自己的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        \"\"\"\n",
    "        初始化数据集，X_data 和 Y_data 是两个列表或数组\n",
    "        X_data: 输入特征\n",
    "        Y_data: 目标标签\n",
    "        \"\"\"\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集的大小\"\"\"\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"返回指定索引的数据\"\"\"\n",
    "        x = torch.tensor(self.X_data[idx], dtype=torch.float32)  # 转换为 Tensor\n",
    "        y = torch.tensor(self.Y_data[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# 示例数据\n",
    "X_data = [[1, 2], [3, 4], [5, 6], [7, 8]]  # 输入特征\n",
    "Y_data = [1, 0, 1, 0]  # 目标标签\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MyDataset(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 DataLoader 加载数据\n",
    "\n",
    "DataLoader 是 PyTorch 提供的一个重要工具，用于从 Dataset 中按批次（batch）加载数据。\n",
    "\n",
    "DataLoader 允许我们批量读取数据并进行多线程加载，从而提高训练效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建 DataLoader 实例，batch_size 设置每次加载的样本数量\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 打印加载的数据\n",
    "for epoch in range(1):\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f'Batch {batch_idx + 1}:')\n",
    "        print(f'Inputs: {inputs}')\n",
    "        print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次循环中，DataLoader 会返回一个批次的数据，包括输入特征（inputs）和目标标签（labels）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size: 每次加载的样本数量。\n",
    "\n",
    "- shuffle: 是否对数据进行洗牌，通常训练时需要将数据打乱。\n",
    "\n",
    "- drop_last: 如果数据集中的样本数不能被 batch_size 整除，设置为 True 时，丢弃最后一个不完整的 batch。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理与数据增强\n",
    "\n",
    "数据预处理和增强对于提高模型的性能至关重要。\n",
    "\n",
    "PyTorch 提供了 torchvision.transforms 模块来进行常见的图像预处理和增强操作，如旋转、裁剪、归一化等。\n",
    "\n",
    "常见的图像预处理操作:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 定义数据预处理的流水线\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((128, 128)),  # 将图像调整为 128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为张量\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),  # 标准化\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 加载图像\n",
    "image = Image.open(\"image.jpg\")\n",
    "\n",
    "# 应用预处理\n",
    "image_tensor = transform(image)\n",
    "print(image_tensor.shape)  # 输出张量的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transforms.Compose()：将多个变换操作组合在一起。\n",
    "\n",
    "- transforms.Resize()：调整图像大小。\n",
    " \n",
    "- transforms.ToTensor()：将图像转换为 PyTorch 张量，值会被归一化到 [0, 1] 范围。\n",
    "\n",
    "- transforms.Normalize()：标准化图像数据，通常使用预训练模型时需要进行标准化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像数据增强\n",
    "\n",
    "数据增强技术通过对训练数据进行随机变换，增加数据的多样性，帮助模型更好地泛化。例如，随机翻转、旋转、裁剪等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "        transforms.RandomRotation(30),  # 随机旋转 30 度\n",
    "        transforms.RandomResizedCrop(128),  # 随机裁剪并调整为 128x128\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些数据增强方法可以通过 transforms.Compose() 组合使用，保证每个图像在训练时具有不同的变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载图像数据集\n",
    "\n",
    "对于图像数据集，torchvision.datasets 提供了许多常见数据集（如 CIFAR-10、ImageNet、MNIST 等）以及用于加载图像数据的工具。\n",
    "\n",
    "加载 MNIST 数据集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义预处理操作\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # 对灰度图像进行标准化\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 下载并加载 MNIST 数据集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 迭代训练数据\n",
    "for inputs, labels in train_loader:\n",
    "    print(inputs.shape)  # 每个批次的输入数据形状\n",
    "    print(labels.shape)  # 每个批次的标签形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- datasets.MNIST() 会自动下载 MNIST 数据集并加载。\n",
    "\n",
    "-  transform 参数允许我们对数据进行预处理。\n",
    "\n",
    "- train=True 和 train=False 分别表示训练集和测试集。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用多个数据源（Multi-source Dataset）\n",
    "\n",
    "如果你的数据集由多个文件、多个来源（例如多个图像文件夹）组成，可以通过继承 Dataset 类自定义加载多个数据源。\n",
    "\n",
    "PyTorch 提供了 ConcatDataset 和 ChainDataset 等类来连接多个数据集。\n",
    "\n",
    "例如，假设我们有多个图像文件夹的数据，可以将它们合并为一个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# 假设 dataset1 和 dataset2 是两个 Dataset 对象\n",
    "combined_dataset = ConcatDataset([dataset1, dataset2])\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
