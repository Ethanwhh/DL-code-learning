{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47baa4aa-af80-4420-9297-55d43fcafcce",
   "metadata": {},
   "source": [
    "# PyTorch 张量（Tensor）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0346d14-6839-420e-91be-0932e8c46b33",
   "metadata": {},
   "source": [
    "张量是一个多维数组，可以是标量、向量、矩阵或更高维度的数据结构。\n",
    "\n",
    "在 PyTorch 中，张量（Tensor）是数据的核心表示形式，类似于 NumPy 的多维数组，但具有更强大的功能，例如支持 GPU 加速和自动梯度计算。\n",
    "\n",
    "张量支持多种数据类型（整型、浮点型、布尔型等）。\n",
    "\n",
    "张量可以存储在 CPU 或 GPU 中，GPU 张量可显著加速计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e01e93-8cfa-475d-9982-a7cef1ce6d6c",
   "metadata": {},
   "source": [
    "说明：\n",
    "\n",
    "- 1D Tensor / Vector（一维张量/向量）: 最基本的张量形式，可以看作是一个数组。\n",
    "\n",
    "- 2D Tensor / Matrix（二维张量/矩阵）: 二维数组，通常用于表示矩阵。\n",
    "\n",
    "- 3D Tensor / Cube（三维张量/立方体）: 三维数组，可以看作是由多个矩阵堆叠而成的立方体。\n",
    "\n",
    "- 4D Tensor / Vector of Cubes（四维张量/立方体向量）: 四维数组，可以看作是由多个立方体组成的向量。\n",
    "\n",
    "- 5D Tensor / Matrix of Cubes（五维张量/立方体矩阵）: 五维数组，可以看作是由多个4D张量组成的矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ceddf-5788-4cec-a5cd-8a96de3a3437",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "张量创建的方式有：\n",
    "\n",
    "|方法|说明|示例代码|\n",
    "|----|----|-------|\n",
    "|torch.tensor(data)|从 Python 列表或 NumPy 数组创建张量。|x = torch.tensor([[1, 2], [3, 4]])|\n",
    "|torch.zeros(size)|创建一个全为零的张量。|x = torch.zeros((2, 3))|\n",
    "|torch.ones(size)|创建一个全为 1 的张量。|x = torch.ones((2, 3))|\n",
    "|torch.empty(size)|创建一个未初始化的张量。|x = torch.empty((2, 3))|\n",
    "|torch.rand(size)|创建一个服从均匀分布的随机张量，值在 [0, 1)。|x = torch.rand((2, 3))|\n",
    "|torch.randn(size)|创建一个服从正态分布的随机张量，均值为 0，标准差为 1。|x = torch.randn((2, 3))|\n",
    "|torch.arange(start, end, step)|创建一个一维序列张量，类似于 Python 的 range。|x = torch.arange(0, 10, 2)|\n",
    "|torch.linspace(start, end, steps)|创建一个在指定范围内等间隔的序列张量。|x = torch.linspace(0, 1, 5)|\n",
    "|torch.eye(size)|创建一个单位矩阵（对角线为 1，其他为 0）。|x = torch.eye(3)|\n",
    "|torch.from_numpy(ndarray)|将 NumPy 数组转换为张量。|x = torch.from_numpy(np.array([1, 2, 3]))|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ee45c-75c3-4743-ba09-b5b5d0c01dca",
   "metadata": {},
   "source": [
    "使用 torch.tensor() 函数，你可以将一个列表或数组转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ac16a2-f71b-4ac9-9d74-3df9f7f37024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T13:45:20.348857Z",
     "iopub.status.busy": "2024-12-27T13:45:20.348510Z",
     "iopub.status.idle": "2024-12-27T13:45:21.363732Z",
     "shell.execute_reply": "2024-12-27T13:45:21.362839Z",
     "shell.execute_reply.started": "2024-12-27T13:45:20.348827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247c03f-f9de-4dc8-afdc-3fa7f0f08a13",
   "metadata": {},
   "source": [
    "如果你有一个 NumPy 数组，可以使用 torch.from_numpy() 将其转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43536776-908e-4d91-be3a-9ec9c2b20bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T13:47:23.118852Z",
     "iopub.status.busy": "2024-12-27T13:47:23.118437Z",
     "iopub.status.idle": "2024-12-27T13:47:23.122588Z",
     "shell.execute_reply": "2024-12-27T13:47:23.122147Z",
     "shell.execute_reply.started": "2024-12-27T13:47:23.118829Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a10aac-7e2f-44ac-ae46-b9310ebcf726",
   "metadata": {},
   "source": [
    "创建 2D 张量（矩阵）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81aaa935-319a-46c8-bb73-a19256ae6325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T13:48:10.893544Z",
     "iopub.status.busy": "2024-12-27T13:48:10.893191Z",
     "iopub.status.idle": "2024-12-27T13:48:10.897789Z",
     "shell.execute_reply": "2024-12-27T13:48:10.897329Z",
     "shell.execute_reply.started": "2024-12-27T13:48:10.893524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Tensor (Matrix):\n",
      " tensor([[-9,  4,  2,  5,  7],\n",
      "        [ 3,  0, 12,  8,  6],\n",
      "        [ 1, 23, -6, 45,  2],\n",
      "        [22,  3, -1, 72,  6]])\n",
      "Shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_2d = torch.tensor([\n",
    "    [-9, 4, 2, 5, 7],\n",
    "    [3, 0, 12, 8, 6],\n",
    "    [1, 23, -6, 45, 2],\n",
    "    [22, 3, -1, 72, 6]\n",
    "])\n",
    "print(\"2D Tensor (Matrix):\\n\", tensor_2d)\n",
    "print(\"Shape:\", tensor_2d.shape)  # 形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c2c31-3c91-46fe-8bb2-743b65ef74bd",
   "metadata": {},
   "source": [
    "其他维度的创建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedf4027-6e3c-40a0-9707-f5ad15359c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T13:48:38.897315Z",
     "iopub.status.busy": "2024-12-27T13:48:38.896962Z",
     "iopub.status.idle": "2024-12-27T13:48:38.904619Z",
     "shell.execute_reply": "2024-12-27T13:48:38.904166Z",
     "shell.execute_reply.started": "2024-12-27T13:48:38.897295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Tensor (Cube):\n",
      " tensor([[[ -9,   4,   2,   5,   7],\n",
      "         [  3,   0,  12,   8,   6],\n",
      "         [  1,  23,  -6,  45,   2],\n",
      "         [ 22,   3,  -1,  72,   6]],\n",
      "\n",
      "        [[  1,  14,  12,  15,  17],\n",
      "         [ 13,  10,  22,  18,  16],\n",
      "         [ 11,  33,   4,  55,  12],\n",
      "         [ 32,  13,   9,  82,  16]],\n",
      "\n",
      "        [[-14,  -1,  -3,   0,   2],\n",
      "         [ -2,  -5,   7,   3,   1],\n",
      "         [ -4,  18, -11,  40,  -3],\n",
      "         [ 17,  -2,  -6,  67,   1]]])\n",
      "Shape: torch.Size([3, 4, 5])\n",
      "4D Tensor (Vector of Cubes):\n",
      " tensor([[[[ -9,   4,   2,   5,   7],\n",
      "          [  3,   0,  12,   8,   6],\n",
      "          [  1,  23,  -6,  45,   2],\n",
      "          [ 22,   3,  -1,  72,   6]],\n",
      "\n",
      "         [[  1,  14,  12,  15,  17],\n",
      "          [ 13,  10,  22,  18,  16],\n",
      "          [ 11,  33,   4,  55,  12],\n",
      "          [ 32,  13,   9,  82,  16]],\n",
      "\n",
      "         [[-14,  -1,  -3,   0,   2],\n",
      "          [ -2,  -5,   7,   3,   1],\n",
      "          [ -4,  18, -11,  40,  -3],\n",
      "          [ 17,  -2,  -6,  67,   1]]],\n",
      "\n",
      "\n",
      "        [[[ 91, 104, 102, 105, 107],\n",
      "          [103, 100, 112, 108, 106],\n",
      "          [101, 123,  94, 145, 102],\n",
      "          [122, 103,  99, 172, 106]],\n",
      "\n",
      "         [[101, 114, 112, 115, 117],\n",
      "          [113, 110, 122, 118, 116],\n",
      "          [111, 133, 104, 155, 112],\n",
      "          [132, 113, 109, 182, 116]],\n",
      "\n",
      "         [[ 86,  99,  97, 100, 102],\n",
      "          [ 98,  95, 107, 103, 101],\n",
      "          [ 96, 118,  89, 140,  97],\n",
      "          [117,  98,  94, 167, 101]]]])\n",
      "Shape: torch.Size([2, 3, 4, 5])\n",
      "5D Tensor (Matrix of Cubes):\n",
      " tensor([[[[[  -9,    4,    2,    5,    7],\n",
      "           [   3,    0,   12,    8,    6],\n",
      "           [   1,   23,   -6,   45,    2],\n",
      "           [  22,    3,   -1,   72,    6]],\n",
      "\n",
      "          [[   1,   14,   12,   15,   17],\n",
      "           [  13,   10,   22,   18,   16],\n",
      "           [  11,   33,    4,   55,   12],\n",
      "           [  32,   13,    9,   82,   16]],\n",
      "\n",
      "          [[ -14,   -1,   -3,    0,    2],\n",
      "           [  -2,   -5,    7,    3,    1],\n",
      "           [  -4,   18,  -11,   40,   -3],\n",
      "           [  17,   -2,   -6,   67,    1]]],\n",
      "\n",
      "\n",
      "         [[[  91,  104,  102,  105,  107],\n",
      "           [ 103,  100,  112,  108,  106],\n",
      "           [ 101,  123,   94,  145,  102],\n",
      "           [ 122,  103,   99,  172,  106]],\n",
      "\n",
      "          [[ 101,  114,  112,  115,  117],\n",
      "           [ 113,  110,  122,  118,  116],\n",
      "           [ 111,  133,  104,  155,  112],\n",
      "           [ 132,  113,  109,  182,  116]],\n",
      "\n",
      "          [[  86,   99,   97,  100,  102],\n",
      "           [  98,   95,  107,  103,  101],\n",
      "           [  96,  118,   89,  140,   97],\n",
      "           [ 117,   98,   94,  167,  101]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 991, 1004, 1002, 1005, 1007],\n",
      "           [1003, 1000, 1012, 1008, 1006],\n",
      "           [1001, 1023,  994, 1045, 1002],\n",
      "           [1022, 1003,  999, 1072, 1006]],\n",
      "\n",
      "          [[1001, 1014, 1012, 1015, 1017],\n",
      "           [1013, 1010, 1022, 1018, 1016],\n",
      "           [1011, 1033, 1004, 1055, 1012],\n",
      "           [1032, 1013, 1009, 1082, 1016]],\n",
      "\n",
      "          [[ 986,  999,  997, 1000, 1002],\n",
      "           [ 998,  995, 1007, 1003, 1001],\n",
      "           [ 996, 1018,  989, 1040,  997],\n",
      "           [1017,  998,  994, 1067, 1001]]],\n",
      "\n",
      "\n",
      "         [[[1091, 1104, 1102, 1105, 1107],\n",
      "           [1103, 1100, 1112, 1108, 1106],\n",
      "           [1101, 1123, 1094, 1145, 1102],\n",
      "           [1122, 1103, 1099, 1172, 1106]],\n",
      "\n",
      "          [[1101, 1114, 1112, 1115, 1117],\n",
      "           [1113, 1110, 1122, 1118, 1116],\n",
      "           [1111, 1133, 1104, 1155, 1112],\n",
      "           [1132, 1113, 1109, 1182, 1116]],\n",
      "\n",
      "          [[1086, 1099, 1097, 1100, 1102],\n",
      "           [1098, 1095, 1107, 1103, 1101],\n",
      "           [1096, 1118, 1089, 1140, 1097],\n",
      "           [1117, 1098, 1094, 1167, 1101]]]]])\n",
      "Shape: torch.Size([2, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 创建 3D 张量（立方体）\n",
    "tensor_3d = torch.stack([tensor_2d, tensor_2d + 10, tensor_2d - 5])  # 堆叠 3 个 2D 张量\n",
    "print(\"3D Tensor (Cube):\\n\", tensor_3d)\n",
    "print(\"Shape:\", tensor_3d.shape)  # 形状\n",
    "\n",
    "# 创建 4D 张量（向量的立方体）\n",
    "tensor_4d = torch.stack([tensor_3d, tensor_3d + 100])  # 堆叠 2 个 3D 张量\n",
    "print(\"4D Tensor (Vector of Cubes):\\n\", tensor_4d)\n",
    "print(\"Shape:\", tensor_4d.shape)  # 形状\n",
    "\n",
    "# 创建 5D 张量（矩阵的立方体）\n",
    "tensor_5d = torch.stack([tensor_4d, tensor_4d + 1000])  # 堆叠 2 个 4D 张量\n",
    "print(\"5D Tensor (Matrix of Cubes):\\n\", tensor_5d)\n",
    "print(\"Shape:\", tensor_5d.shape)  # 形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1c110-0ccb-4d4f-be3a-8f67a0650c42",
   "metadata": {},
   "source": [
    "## 张量的属性\n",
    "\n",
    "张量的属性如下表：\n",
    "\n",
    "|属性|说明|示例|\n",
    "|----|----|----|\n",
    "|.shape|获取张量的形状|tensor.shape|\n",
    "|.size()|获取张量的形状|tensor.size()|\n",
    "|.dtype|获取张量的数据类型|tensor.dtype|\n",
    "|.device|查看张量所在的设备 (CPU/GPU)|tensor.device|\n",
    "|.dim()|获取张量的维度数|tensor.dim()|\n",
    "|.requires_grad|是否启用梯度计算|tensor.requires_grad|\n",
    "|.numel()|获取张量中的元素总数|tensor.numel()|\n",
    "|.is_cuda|检查张量是否在 GPU 上|tensor.is_cuda|\n",
    "|.T|获取张量的转置（适用于 2D 张量）|tensor.T|\n",
    "|.item()|获取单元素张量的值|tensor.item()|\n",
    "|.is_contiguous()|检查张量是否连续存储|tensor.is_contiguous()|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59828151-8d5d-4a8b-9d5c-43b973255d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T13:53:22.540711Z",
     "iopub.status.busy": "2024-12-27T13:53:22.540381Z",
     "iopub.status.idle": "2024-12-27T13:53:22.548447Z",
     "shell.execute_reply": "2024-12-27T13:53:22.547846Z",
     "shell.execute_reply.started": "2024-12-27T13:53:22.540692Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Shape: torch.Size([2, 3])\n",
      "Size: torch.Size([2, 3])\n",
      "Data Type: torch.float32\n",
      "Device: cpu\n",
      "Dimensions: 2\n",
      "Total Elements: 6\n",
      "Requires Grad: False\n",
      "Is CUDA: False\n",
      "Is Contiguous: True\n",
      "Single Element Value: 42\n",
      "Transposed Tensor:\n",
      " tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 2D 张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# 张量的属性\n",
    "print(\"Tensor:\\n\", tensor)\n",
    "print(\"Shape:\", tensor.shape)  # 获取形状\n",
    "print(\"Size:\", tensor.size())  # 获取形状（另一种方法）\n",
    "print(\"Data Type:\", tensor.dtype)  # 数据类型\n",
    "print(\"Device:\", tensor.device)  # 设备\n",
    "print(\"Dimensions:\", tensor.dim())  # 维度数\n",
    "print(\"Total Elements:\", tensor.numel())  # 元素总数\n",
    "print(\"Requires Grad:\", tensor.requires_grad)  # 是否启用梯度\n",
    "print(\"Is CUDA:\", tensor.is_cuda)  # 是否在 GPU 上\n",
    "print(\"Is Contiguous:\", tensor.is_contiguous())  # 是否连续存储\n",
    "\n",
    "# 获取单元素值\n",
    "single_value = torch.tensor(42)\n",
    "print(\"Single Element Value:\", single_value.item())\n",
    "\n",
    "# 转置张量\n",
    "tensor_T = tensor.T\n",
    "print(\"Transposed Tensor:\\n\", tensor_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae86b0b-2bbd-4aac-8a83-f03dd08c39cc",
   "metadata": {},
   "source": [
    "## 张量的操作\n",
    "\n",
    "张量操作方法说明如下。\n",
    "\n",
    "基础操作：\n",
    "\n",
    "|操作|说明|示例代码|\n",
    "|----|----|-------|\n",
    "|+, -, *, / |元素级加法、减法、乘法、除法。|z = x + y|\n",
    "|torch.matmul(x, y)|矩阵乘法。|z = torch.matmul(x, y)|\n",
    "|torch.dot(x, y)|向量点积（仅适用于 1D 张量）。|z = torch.dot(x, y)|\n",
    "|torch.sum(x)|求和。|z = torch.sum(x)|\n",
    "|torch.mean(x)|求均值。|z = torch.mean(x)|\n",
    "|torch.max(x)|求最大值。|z = torch.max(x)|\n",
    "|torch.min(x)|求最小值。|z = torch.min(x)|\n",
    "|torch.argmax(x, dim)|返回最大值的索引（指定维度）。|z = torch.argmax(x, dim=1)|\n",
    "|torch.softmax(x, dim)|计算 softmax（指定维度）。|z = torch.softmax(x, dim=1)|\n",
    "\n",
    "形状操作:\n",
    "\n",
    "|操作|说明|示例代码|\n",
    "|----|----|-------|\n",
    "|x.view(shape)|改变张量的形状（不改变数据）。|z = x.view(3, 4)|\n",
    "|x.reshape(shape)|类似于 view，但更灵活。|z = x.reshape(3, 4)|\n",
    "|x.t()|转置矩阵。|z = x.t()|\n",
    "|x.unsqueeze(dim)|在指定维度添加一个维度。|z = x.unsqueeze(0)|\n",
    "|x.squeeze(dim)|去掉指定维度为 1 的维度。|z = x.squeeze(0)|\n",
    "|torch.cat((x, y), dim)|按指定维度连接多个张量。|z = torch.cat((x, y), dim=1)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f66107e-47a2-4c1e-a35a-bf8af7843f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T14:03:05.673271Z",
     "iopub.status.busy": "2024-12-27T14:03:05.672917Z",
     "iopub.status.idle": "2024-12-27T14:03:05.683464Z",
     "shell.execute_reply": "2024-12-27T14:03:05.683005Z",
     "shell.execute_reply.started": "2024-12-27T14:03:05.673250Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "【索引和切片】\n",
      "获取第一行: tensor([1., 2., 3.])\n",
      "获取第一行第一列的元素: tensor(1.)\n",
      "获取第二列的所有元素: tensor([2., 5.])\n",
      "\n",
      "【形状变换】\n",
      "改变形状后的张量:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "展平后的张量:\n",
      " tensor([1., 2., 3., 4., 5., 6.])\n",
      "\n",
      "【数学运算】\n",
      "张量加 10:\n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n",
      "张量乘 2:\n",
      " tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "张量元素的和: 21.0\n",
      "\n",
      "【与其他张量操作】\n",
      "另一个张量:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "矩阵乘法结果:\n",
      " tensor([[ 6.,  6.],\n",
      "        [15., 15.]])\n",
      "\n",
      "【条件判断和筛选】\n",
      "大于 3 的元素的布尔掩码:\n",
      " tensor([[False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "大于 3 的元素:\n",
      " tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 2D 张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(\"原始张量:\\n\", tensor)\n",
    "\n",
    "# 1. **索引和切片操作**\n",
    "print(\"\\n【索引和切片】\")\n",
    "print(\"获取第一行:\", tensor[0])  # 获取第一行\n",
    "print(\"获取第一行第一列的元素:\", tensor[0, 0])  # 获取特定元素\n",
    "print(\"获取第二列的所有元素:\", tensor[:, 1])  # 获取第二列所有元素\n",
    "\n",
    "# 2. **形状变换操作**\n",
    "print(\"\\n【形状变换】\")\n",
    "reshaped = tensor.view(3, 2)  # 改变张量形状为 3x2\n",
    "print(\"改变形状后的张量:\\n\", reshaped)\n",
    "flattened = tensor.flatten()  # 将张量展平成一维\n",
    "print(\"展平后的张量:\\n\", flattened)\n",
    "\n",
    "# 3. **数学运算操作**\n",
    "print(\"\\n【数学运算】\")\n",
    "tensor_add = tensor + 10  # 张量加法\n",
    "print(\"张量加 10:\\n\", tensor_add)\n",
    "tensor_mul = tensor * 2  # 张量乘法\n",
    "print(\"张量乘 2:\\n\", tensor_mul)\n",
    "tensor_sum = tensor.sum()  # 计算所有元素的和\n",
    "print(\"张量元素的和:\", tensor_sum.item())\n",
    "\n",
    "# 4. **与其他张量的操作**\n",
    "print(\"\\n【与其他张量操作】\")\n",
    "tensor2 = torch.tensor([[1, 1, 1], [1, 1, 1]], dtype=torch.float32)\n",
    "print(\"另一个张量:\\n\", tensor2)\n",
    "tensor_dot = torch.matmul(tensor, tensor2.T)  # 张量矩阵乘法\n",
    "print(\"矩阵乘法结果:\\n\", tensor_dot)\n",
    "\n",
    "# 5. **条件判断和筛选**\n",
    "print(\"\\n【条件判断和筛选】\")\n",
    "mask = tensor > 3  # 创建一个布尔掩码\n",
    "print(\"大于 3 的元素的布尔掩码:\\n\", mask)\n",
    "filtered_tensor = tensor[tensor > 3]  # 筛选出符合条件的元素\n",
    "print(\"大于 3 的元素:\\n\", filtered_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f46d8-0918-4b5b-98da-e96e8c2ba07b",
   "metadata": {},
   "source": [
    "## 张量的 GPU 加速"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503eabbb-2721-486b-bfc7-7977da946bee",
   "metadata": {},
   "source": [
    "将张量转移到 GPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17d53e-2229-494f-bce3-002f7531043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d320242-c0ef-424f-a09f-9bca08fb6545",
   "metadata": {},
   "source": [
    "检查 GPU 是否可用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dcc2a9-aebf-48a2-9d6b-840f5006b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()  # 返回 True 或 False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14eae5-e884-43c7-bd6b-e7119e82c5a3",
   "metadata": {},
   "source": [
    "## 张量与 NumPy 的互操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89a8b4-30f6-4ed8-a985-83f2b4dd5068",
   "metadata": {},
   "source": [
    "张量与 NumPy 的互操作如下表所示：\n",
    "\n",
    "|操作|说明|示例代码|\n",
    "|----|----|-------|\n",
    "|torch.from_numpy(ndarray)|将 NumPy 数组转换为张量。|x = torch.from_numpy(np_array)|\n",
    "|x.numpy()|将张量转换为 NumPy 数组（仅限 CPU 张量）。|np_array = x.numpy()|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3efe8e71-bf06-4c98-97a5-ff7e37f7ac00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:00:26.502686Z",
     "iopub.status.busy": "2024-12-27T15:00:26.502357Z",
     "iopub.status.idle": "2024-12-27T15:00:26.511440Z",
     "shell.execute_reply": "2024-12-27T15:00:26.510971Z",
     "shell.execute_reply.started": "2024-12-27T15:00:26.502666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NumPy 转为 PyTorch 张量\n",
      "NumPy 数组:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "转换后的 PyTorch 张量:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "修改后的 NumPy 数组:\n",
      " [[100   2   3]\n",
      " [  4   5   6]]\n",
      "PyTorch 张量也会同步变化:\n",
      " tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]])\n",
      "\n",
      "2. PyTorch 张量转为 NumPy 数组\n",
      "PyTorch 张量:\n",
      " tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "转换后的 NumPy 数组:\n",
      " [[ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "修改后的 PyTorch 张量:\n",
      " tensor([[77.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "NumPy 数组也会同步变化:\n",
      " [[77.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "\n",
      "3. 使用 clone() 保证独立数据\n",
      "原始张量:\n",
      " tensor([[13., 14., 15.],\n",
      "        [16., 17., 18.]])\n",
      "修改后的张量:\n",
      " tensor([[ 0., 14., 15.],\n",
      "        [16., 17., 18.]])\n",
      "NumPy 数组（不会同步变化）:\n",
      " [[13. 14. 15.]\n",
      " [16. 17. 18.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. NumPy 数组转换为 PyTorch 张量\n",
    "print(\"1. NumPy 转为 PyTorch 张量\")\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"NumPy 数组:\\n\", numpy_array)\n",
    "\n",
    "# 使用 torch.from_numpy() 将 NumPy 数组转换为张量\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"转换后的 PyTorch 张量:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 修改 NumPy 数组，观察张量的变化（共享内存）\n",
    "numpy_array[0, 0] = 100\n",
    "print(\"修改后的 NumPy 数组:\\n\", numpy_array)\n",
    "print(\"PyTorch 张量也会同步变化:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 2. PyTorch 张量转换为 NumPy 数组\n",
    "print(\"\\n2. PyTorch 张量转为 NumPy 数组\")\n",
    "tensor = torch.tensor([[7, 8, 9], [10, 11, 12]], dtype=torch.float32)\n",
    "print(\"PyTorch 张量:\\n\", tensor)\n",
    "\n",
    "# 使用 tensor.numpy() 将张量转换为 NumPy 数组\n",
    "numpy_from_tensor = tensor.numpy()\n",
    "print(\"转换后的 NumPy 数组:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 修改张量，观察 NumPy 数组的变化（共享内存）\n",
    "tensor[0, 0] = 77\n",
    "print(\"修改后的 PyTorch 张量:\\n\", tensor)\n",
    "print(\"NumPy 数组也会同步变化:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 3. 注意：不共享内存的情况（需要复制数据）\n",
    "print(\"\\n3. 使用 clone() 保证独立数据\")\n",
    "tensor_independent = torch.tensor([[13, 14, 15], [16, 17, 18]], dtype=torch.float32)\n",
    "numpy_independent = tensor_independent.clone().numpy()  # 使用 clone 复制数据\n",
    "print(\"原始张量:\\n\", tensor_independent)\n",
    "tensor_independent[0, 0] = 0  # 修改张量数据\n",
    "print(\"修改后的张量:\\n\", tensor_independent)\n",
    "print(\"NumPy 数组（不会同步变化）:\\n\", numpy_independent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
