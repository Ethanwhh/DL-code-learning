{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6a28bc-c167-438a-aaff-746d064685e1",
   "metadata": {},
   "source": [
    "1. 准备数据\n",
    "\n",
    "- 对于每个名字需要得到一个向量\n",
    "\n",
    "- 通过ASCII对于每个名字的每个字符都得到一个one-hot vector\n",
    "\n",
    "- 由于输入是矩阵所以需要padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eca81c8-59f5-4031-bbd9-f83d361aac23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:49:26.072766Z",
     "iopub.status.busy": "2024-12-17T02:49:26.072465Z",
     "iopub.status.idle": "2024-12-17T02:49:28.716283Z",
     "shell.execute_reply": "2024-12-17T02:49:28.715753Z",
     "shell.execute_reply.started": "2024-12-17T02:49:26.072747Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, is_train_set):\n",
    "        filename = './names_train.csv.gz' if is_train_set else './names_test.csv.gz'\n",
    "        with gzip.open(filename, 'rt') as f:    # r表示只读，从文件头开始 t表示文本模式\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    def __getitem__(self, index):       # 根据索引拿到的是 名字，国家的索引\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n",
    "\n",
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 50\n",
    "N_CHARS = 128   # 这个是为了构造嵌入层\n",
    "\n",
    "trainSet = NameDataset(is_train_set=True)\n",
    "trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testSet = NameDataset(is_train_set=False)\n",
    "testLoader = DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRY = trainSet.getCountriesNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf884f-1616-46dc-ac0f-73611d2bf93b",
   "metadata": {},
   "source": [
    "2. 构建模型\n",
    "\n",
    "    GRU的维度\n",
    "\n",
    "    输入维度：\n",
    "\n",
    "    𝑖𝑛𝑝𝑢𝑡: (𝑠𝑒𝑞𝐿𝑒𝑛, 𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒, ℎ𝑖𝑑𝑑𝑒𝑛𝑆𝑖𝑧𝑒)\n",
    "\n",
    "    hidden: (nLayers * nDirections, batchSize, hiddenSize)\n",
    "\n",
    "    输出维度：\n",
    "\n",
    "    output: (seqLen, batchSize, hiddenSize * nDirections)\n",
    "\n",
    "    hidden: (nLayers * nDirections, batchSize, hiddenSize)\n",
    "    \n",
    "    GRU处理时可以使用pack_padded_sequence提高效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc06226e-33d3-4be4-8550-af415ade4bc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:49:32.812671Z",
     "iopub.status.busy": "2024-12-17T02:49:32.812296Z",
     "iopub.status.idle": "2024-12-17T02:49:32.818776Z",
     "shell.execute_reply": "2024-12-17T02:49:32.818227Z",
     "shell.execute_reply.started": "2024-12-17T02:49:32.812651Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1   # 使用双向的GRU\n",
    "\n",
    "        # 嵌入层（𝑠𝑒𝑞𝐿𝑒𝑛, 𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒） --> (𝑠𝑒𝑞𝐿𝑒𝑛, 𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒, hidden_size)\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, input, seq_lengths):\n",
    "        # input shape : B x S -> S x B\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embedding(input)\n",
    "\n",
    "        # pack them up\n",
    "        gru_input = torch.nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths)\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71635e8-abf1-4f3f-b420-2cc1da8d77de",
   "metadata": {},
   "source": [
    "3. 数据转化成Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5ea552-482e-4d4b-8791-1bc2fc49687f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:49:35.311860Z",
     "iopub.status.busy": "2024-12-17T02:49:35.311545Z",
     "iopub.status.idle": "2024-12-17T02:49:35.316723Z",
     "shell.execute_reply": "2024-12-17T02:49:35.316269Z",
     "shell.execute_reply.started": "2024-12-17T02:49:35.311839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [s1[0] for s1 in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    # make tensor of name, BatchSize * seqLen\n",
    "    # 他这里补零的方式先将所有的0 Tensor给初始化出来，然后在每行前面填充每个名字\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    # print(\"seq_lengths.max:\", seq_lengths.max())\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    # 将名字长度降序排列，并且返回降序之后的长度在原tensor中的小标perm_idx\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    # 这个Tensor中的类似于列表中切片的方法神奇啊，直接返回下标对应的元素，相等于排序了\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    # 返回排序之后名字Tensor，排序之后的名字长度Tensor，排序之后的国家名字Tensor\n",
    "    return seq_tensor, seq_lengths, countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f0cae-9272-49e4-a6cd-eab64f5b02e8",
   "metadata": {},
   "source": [
    "4. 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0de767-c9d0-4fd3-97d7-5aed03f3bbbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:49:37.327698Z",
     "iopub.status.busy": "2024-12-17T02:49:37.327366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50 epochs...\n",
      "[0m 4s] Epoch 1 [2560/13374] loss=0.008852446731179953\n",
      "[0m 5s] Epoch 1 [5120/13374] loss=0.0076263871043920515\n",
      "[0m 5s] Epoch 1 [7680/13374] loss=0.006879185559228063\n",
      "[0m 6s] Epoch 1 [10240/13374] loss=0.006384475715458393\n",
      "[0m 7s] Epoch 1 [12800/13374] loss=0.006069569792598486\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 4401/6700 65.69%\n",
      "[0m 9s] Epoch 2 [2560/13374] loss=0.004185331147164106\n",
      "[0m 9s] Epoch 2 [5120/13374] loss=0.004084936599247158\n",
      "[0m 10s] Epoch 2 [7680/13374] loss=0.003991990520929297\n",
      "[0m 11s] Epoch 2 [10240/13374] loss=0.0038965292391367258\n",
      "[0m 12s] Epoch 2 [12800/13374] loss=0.003809977634809911\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 4955/6700 73.96%\n",
      "[0m 14s] Epoch 3 [2560/13374] loss=0.0032922630896791817\n",
      "[0m 14s] Epoch 3 [5120/13374] loss=0.0032620920799672605\n",
      "[0m 15s] Epoch 3 [7680/13374] loss=0.0031723380632077652\n",
      "[0m 16s] Epoch 3 [10240/13374] loss=0.003083957324270159\n",
      "[0m 16s] Epoch 3 [12800/13374] loss=0.0030278698867186905\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5239/6700 78.19%\n",
      "[0m 18s] Epoch 4 [2560/13374] loss=0.0026384722208604217\n",
      "[0m 19s] Epoch 4 [5120/13374] loss=0.0026144236675463618\n",
      "[0m 19s] Epoch 4 [7680/13374] loss=0.0025851314576963583\n",
      "[0m 20s] Epoch 4 [10240/13374] loss=0.002608572627650574\n",
      "[0m 21s] Epoch 4 [12800/13374] loss=0.00258546594530344\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5352/6700 79.88%\n",
      "[0m 23s] Epoch 5 [2560/13374] loss=0.0022531323484145105\n",
      "[0m 24s] Epoch 5 [5120/13374] loss=0.002230239805066958\n",
      "[0m 25s] Epoch 5 [7680/13374] loss=0.002260400909775247\n",
      "[0m 25s] Epoch 5 [10240/13374] loss=0.002255042619071901\n",
      "[0m 26s] Epoch 5 [12800/13374] loss=0.002258175949100405\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5455/6700 81.42%\n",
      "[0m 28s] Epoch 6 [2560/13374] loss=0.001979941746685654\n",
      "[0m 29s] Epoch 6 [5120/13374] loss=0.001959947351133451\n",
      "[0m 30s] Epoch 6 [7680/13374] loss=0.0019518783859287698\n",
      "[0m 30s] Epoch 6 [10240/13374] loss=0.001981357904151082\n",
      "[0m 31s] Epoch 6 [12800/13374] loss=0.0020070208446122707\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5501/6700 82.10%\n",
      "[0m 33s] Epoch 7 [2560/13374] loss=0.0017500625457614661\n",
      "[0m 33s] Epoch 7 [5120/13374] loss=0.0017839752603322268\n",
      "[0m 34s] Epoch 7 [7680/13374] loss=0.001775973899445186\n",
      "[0m 35s] Epoch 7 [10240/13374] loss=0.0018140912347007544\n",
      "[0m 36s] Epoch 7 [12800/13374] loss=0.0018118494283407927\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5549/6700 82.82%\n",
      "[0m 37s] Epoch 8 [2560/13374] loss=0.0016936392174102366\n",
      "[0m 38s] Epoch 8 [5120/13374] loss=0.0016824223799630999\n",
      "[0m 39s] Epoch 8 [7680/13374] loss=0.0016639747036000093\n",
      "[0m 40s] Epoch 8 [10240/13374] loss=0.001628874585730955\n",
      "[0m 40s] Epoch 8 [12800/13374] loss=0.0016290219011716545\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5581/6700 83.30%\n",
      "[0m 42s] Epoch 9 [2560/13374] loss=0.001482851814944297\n",
      "[0m 43s] Epoch 9 [5120/13374] loss=0.0014768012159038335\n",
      "[0m 44s] Epoch 9 [7680/13374] loss=0.0014656887506134808\n",
      "[0m 44s] Epoch 9 [10240/13374] loss=0.0014589329744921996\n",
      "[0m 45s] Epoch 9 [12800/13374] loss=0.0014770002593286335\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5616/6700 83.82%\n",
      "[0m 47s] Epoch 10 [2560/13374] loss=0.0013114091707393527\n",
      "[0m 48s] Epoch 10 [5120/13374] loss=0.0013637560536153615\n",
      "[0m 48s] Epoch 10 [7680/13374] loss=0.0013539572595618666\n",
      "[0m 49s] Epoch 10 [10240/13374] loss=0.0013611967005999759\n",
      "[0m 50s] Epoch 10 [12800/13374] loss=0.0013530787476338446\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5621/6700 83.90%\n",
      "[0m 52s] Epoch 11 [2560/13374] loss=0.0011667062644846737\n",
      "[0m 53s] Epoch 11 [5120/13374] loss=0.0011923558893613517\n",
      "[0m 54s] Epoch 11 [7680/13374] loss=0.0011686985477960359\n",
      "[0m 55s] Epoch 11 [10240/13374] loss=0.0011879788115038536\n",
      "[0m 55s] Epoch 11 [12800/13374] loss=0.0012082138995174318\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5627/6700 83.99%\n",
      "[0m 57s] Epoch 12 [2560/13374] loss=0.0010003369476180523\n",
      "[0m 58s] Epoch 12 [5120/13374] loss=0.001074828821583651\n",
      "[0m 59s] Epoch 12 [7680/13374] loss=0.0010664467932656406\n",
      "[0m 59s] Epoch 12 [10240/13374] loss=0.0010987046407535672\n",
      "[1m 0s] Epoch 12 [12800/13374] loss=0.0010943339695222677\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5661/6700 84.49%\n",
      "[1m 2s] Epoch 13 [2560/13374] loss=0.0008754862239584327\n",
      "[1m 3s] Epoch 13 [5120/13374] loss=0.0009028030646732077\n",
      "[1m 4s] Epoch 13 [7680/13374] loss=0.0009121784280675153\n",
      "[1m 4s] Epoch 13 [10240/13374] loss=0.0009435551764909178\n",
      "[1m 5s] Epoch 13 [12800/13374] loss=0.0009634471370372921\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5599/6700 83.57%\n",
      "[1m 7s] Epoch 14 [2560/13374] loss=0.0007443450507707894\n",
      "[1m 8s] Epoch 14 [5120/13374] loss=0.000803614326287061\n",
      "[1m 9s] Epoch 14 [7680/13374] loss=0.0008316661716283609\n",
      "[1m 9s] Epoch 14 [10240/13374] loss=0.0008539887683582492\n",
      "[1m 10s] Epoch 14 [12800/13374] loss=0.0008687656128313392\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5631/6700 84.04%\n",
      "[1m 11s] Epoch 15 [2560/13374] loss=0.0006686213018838316\n",
      "[1m 13s] Epoch 15 [5120/13374] loss=0.0007076529029291124\n",
      "[1m 13s] Epoch 15 [7680/13374] loss=0.0007178088766522705\n",
      "[1m 14s] Epoch 15 [10240/13374] loss=0.0007378892434644513\n",
      "[1m 15s] Epoch 15 [12800/13374] loss=0.0007530234067235142\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5651/6700 84.34%\n",
      "[1m 16s] Epoch 16 [2560/13374] loss=0.0006708186992909759\n",
      "[1m 17s] Epoch 16 [5120/13374] loss=0.000646263717499096\n",
      "[1m 17s] Epoch 16 [7680/13374] loss=0.0006608137802686543\n",
      "[1m 18s] Epoch 16 [10240/13374] loss=0.0006605196904274635\n",
      "[1m 18s] Epoch 16 [12800/13374] loss=0.0006677663663867861\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5620/6700 83.88%\n",
      "[1m 20s] Epoch 17 [2560/13374] loss=0.0005415570427430794\n",
      "[1m 21s] Epoch 17 [5120/13374] loss=0.0005626768543152139\n",
      "[1m 22s] Epoch 17 [7680/13374] loss=0.0005584766952476154\n",
      "[1m 23s] Epoch 17 [10240/13374] loss=0.0005690817612048704\n",
      "[1m 23s] Epoch 17 [12800/13374] loss=0.0005884146777680143\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5634/6700 84.09%\n",
      "[1m 25s] Epoch 18 [2560/13374] loss=0.0005066211248049513\n",
      "[1m 25s] Epoch 18 [5120/13374] loss=0.0004869574127951637\n",
      "[1m 26s] Epoch 18 [7680/13374] loss=0.0005097464454593137\n",
      "[1m 27s] Epoch 18 [10240/13374] loss=0.0005177982624445576\n",
      "[1m 27s] Epoch 18 [12800/13374] loss=0.0005258751555811614\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5640/6700 84.18%\n",
      "[1m 29s] Epoch 19 [2560/13374] loss=0.00043293495546095075\n",
      "[1m 30s] Epoch 19 [5120/13374] loss=0.00046487877261824906\n",
      "[1m 30s] Epoch 19 [7680/13374] loss=0.00046740274604720373\n",
      "[1m 31s] Epoch 19 [10240/13374] loss=0.0004717846000858117\n",
      "[1m 32s] Epoch 19 [12800/13374] loss=0.0004680462053511292\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5649/6700 84.31%\n",
      "[1m 33s] Epoch 20 [2560/13374] loss=0.0003753402823349461\n",
      "[1m 34s] Epoch 20 [5120/13374] loss=0.00038643486041110007\n",
      "[1m 35s] Epoch 20 [7680/13374] loss=0.0003841753030428663\n",
      "[1m 35s] Epoch 20 [10240/13374] loss=0.00040622254164190963\n",
      "[1m 36s] Epoch 20 [12800/13374] loss=0.0004262202506652102\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5637/6700 84.13%\n",
      "[1m 37s] Epoch 21 [2560/13374] loss=0.0003923074546037242\n",
      "[1m 38s] Epoch 21 [5120/13374] loss=0.0003878917137626559\n",
      "[1m 39s] Epoch 21 [7680/13374] loss=0.0004008270838918785\n",
      "[1m 40s] Epoch 21 [10240/13374] loss=0.0003974332030338701\n",
      "[1m 40s] Epoch 21 [12800/13374] loss=0.00040620287996716796\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5632/6700 84.06%\n",
      "[1m 42s] Epoch 22 [2560/13374] loss=0.00034404638281557707\n",
      "[1m 43s] Epoch 22 [5120/13374] loss=0.00033662791320239195\n",
      "[1m 43s] Epoch 22 [7680/13374] loss=0.00033495880973835785\n",
      "[1m 44s] Epoch 22 [10240/13374] loss=0.0003453917168371845\n",
      "[1m 45s] Epoch 22 [12800/13374] loss=0.0003457094042096287\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5626/6700 83.97%\n",
      "[1m 46s] Epoch 23 [2560/13374] loss=0.0002854842532542534\n",
      "[1m 47s] Epoch 23 [5120/13374] loss=0.0002893017619499005\n",
      "[1m 47s] Epoch 23 [7680/13374] loss=0.00030863760572780543\n",
      "[1m 48s] Epoch 23 [10240/13374] loss=0.0003110429952357663\n",
      "[1m 49s] Epoch 23 [12800/13374] loss=0.00031703801825642584\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5627/6700 83.99%\n",
      "[1m 50s] Epoch 24 [2560/13374] loss=0.00028217140497872607\n",
      "[1m 51s] Epoch 24 [5120/13374] loss=0.00027952797390753405\n",
      "[1m 52s] Epoch 24 [7680/13374] loss=0.00028965665745393684\n",
      "[1m 53s] Epoch 24 [10240/13374] loss=0.0002945871554402402\n",
      "[1m 54s] Epoch 24 [12800/13374] loss=0.00030211248289560897\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5610/6700 83.73%\n",
      "[1m 55s] Epoch 25 [2560/13374] loss=0.0002387608532444574\n",
      "[1m 56s] Epoch 25 [5120/13374] loss=0.0002582407803856768\n",
      "[1m 57s] Epoch 25 [7680/13374] loss=0.00026526688889134676\n",
      "[1m 58s] Epoch 25 [10240/13374] loss=0.00028455439787649083\n",
      "[1m 59s] Epoch 25 [12800/13374] loss=0.0002968154454720207\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5604/6700 83.64%\n",
      "[2m 1s] Epoch 26 [2560/13374] loss=0.00023335632577072828\n",
      "[2m 2s] Epoch 26 [5120/13374] loss=0.00023304328569793143\n",
      "[2m 3s] Epoch 26 [7680/13374] loss=0.0002484556433046237\n",
      "[2m 3s] Epoch 26 [10240/13374] loss=0.0002556402858317597\n",
      "[2m 4s] Epoch 26 [12800/13374] loss=0.00027245595963904635\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5605/6700 83.66%\n",
      "[2m 6s] Epoch 27 [2560/13374] loss=0.00021834695944562555\n",
      "[2m 7s] Epoch 27 [5120/13374] loss=0.00026084477140102534\n",
      "[2m 7s] Epoch 27 [7680/13374] loss=0.00025685821116591494\n",
      "[2m 8s] Epoch 27 [10240/13374] loss=0.00026025405677501114\n",
      "[2m 9s] Epoch 27 [12800/13374] loss=0.0002637644353671931\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5610/6700 83.73%\n",
      "[2m 10s] Epoch 28 [2560/13374] loss=0.0002302211112692021\n",
      "[2m 11s] Epoch 28 [5120/13374] loss=0.00021460977804963477\n",
      "[2m 12s] Epoch 28 [7680/13374] loss=0.0002298537273115168\n",
      "[2m 13s] Epoch 28 [10240/13374] loss=0.00023945762477524114\n",
      "[2m 14s] Epoch 28 [12800/13374] loss=0.00025019895343575627\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5619/6700 83.87%\n",
      "[2m 15s] Epoch 29 [2560/13374] loss=0.00021057269259472378\n",
      "[2m 16s] Epoch 29 [5120/13374] loss=0.0002479144637618447\n",
      "[2m 17s] Epoch 29 [7680/13374] loss=0.0002411765790990709\n",
      "[2m 17s] Epoch 29 [10240/13374] loss=0.0002495470545909484\n",
      "[2m 18s] Epoch 29 [12800/13374] loss=0.0002489657986734528\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5601/6700 83.60%\n",
      "[2m 20s] Epoch 30 [2560/13374] loss=0.00021887738112127408\n",
      "[2m 21s] Epoch 30 [5120/13374] loss=0.0002251493337098509\n",
      "[2m 22s] Epoch 30 [7680/13374] loss=0.00023938760762879003\n",
      "[2m 23s] Epoch 30 [10240/13374] loss=0.00023213546301121825\n",
      "[2m 24s] Epoch 30 [12800/13374] loss=0.0002391799900215119\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5592/6700 83.46%\n",
      "[2m 25s] Epoch 31 [2560/13374] loss=0.000179987822775729\n",
      "[2m 26s] Epoch 31 [5120/13374] loss=0.00020160638086963445\n",
      "[2m 27s] Epoch 31 [7680/13374] loss=0.00021960142573031286\n",
      "[2m 27s] Epoch 31 [10240/13374] loss=0.00023132726055337117\n",
      "[2m 28s] Epoch 31 [12800/13374] loss=0.00024252567032817751\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5585/6700 83.36%\n",
      "[2m 30s] Epoch 32 [2560/13374] loss=0.00018308741273358463\n",
      "[2m 31s] Epoch 32 [5120/13374] loss=0.0002082682607579045\n",
      "[2m 31s] Epoch 32 [7680/13374] loss=0.0002256204461446032\n",
      "[2m 32s] Epoch 32 [10240/13374] loss=0.00022360086186381522\n",
      "[2m 33s] Epoch 32 [12800/13374] loss=0.00023625183355761693\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5603/6700 83.63%\n",
      "[2m 34s] Epoch 33 [2560/13374] loss=0.00020076640212209895\n",
      "[2m 35s] Epoch 33 [5120/13374] loss=0.00021171291227801704\n",
      "[2m 36s] Epoch 33 [7680/13374] loss=0.00021380162118778874\n",
      "[2m 37s] Epoch 33 [10240/13374] loss=0.00021885613168706186\n",
      "[2m 37s] Epoch 33 [12800/13374] loss=0.0002241360768675804\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5614/6700 83.79%\n",
      "[2m 39s] Epoch 34 [2560/13374] loss=0.00018803527491400017\n",
      "[2m 40s] Epoch 34 [5120/13374] loss=0.0001884821758721955\n",
      "[2m 41s] Epoch 34 [7680/13374] loss=0.00019849102851973537\n",
      "[2m 43s] Epoch 34 [10240/13374] loss=0.00021013256064179587\n",
      "[2m 43s] Epoch 34 [12800/13374] loss=0.00022477702543255873\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5611/6700 83.75%\n",
      "[2m 45s] Epoch 35 [2560/13374] loss=0.00020454625409911388\n",
      "[2m 45s] Epoch 35 [5120/13374] loss=0.00019672676862683147\n",
      "[2m 46s] Epoch 35 [7680/13374] loss=0.00020686838154991468\n",
      "[2m 47s] Epoch 35 [10240/13374] loss=0.00021208249563642312\n",
      "[2m 48s] Epoch 35 [12800/13374] loss=0.00021862752095330506\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5595/6700 83.51%\n",
      "[2m 49s] Epoch 36 [2560/13374] loss=0.00013927264080848545\n",
      "[2m 50s] Epoch 36 [5120/13374] loss=0.0001710710686893435\n",
      "[2m 51s] Epoch 36 [7680/13374] loss=0.00018864839803427457\n",
      "[2m 52s] Epoch 36 [10240/13374] loss=0.00020642875424528028\n",
      "[2m 53s] Epoch 36 [12800/13374] loss=0.00021259344706777482\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5622/6700 83.91%\n",
      "[2m 54s] Epoch 37 [2560/13374] loss=0.00015390190965263172\n",
      "[2m 55s] Epoch 37 [5120/13374] loss=0.00018522398895584046\n",
      "[2m 56s] Epoch 37 [7680/13374] loss=0.0001847038545141307\n",
      "[2m 57s] Epoch 37 [10240/13374] loss=0.0002008064493566053\n",
      "[2m 57s] Epoch 37 [12800/13374] loss=0.0002069559662777465\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5615/6700 83.81%\n",
      "[2m 59s] Epoch 38 [2560/13374] loss=0.00018384127033641562\n",
      "[3m 0s] Epoch 38 [5120/13374] loss=0.0001923910138430074\n",
      "[3m 1s] Epoch 38 [7680/13374] loss=0.00019525810494087638\n",
      "[3m 2s] Epoch 38 [10240/13374] loss=0.00020142918874626047\n",
      "[3m 3s] Epoch 38 [12800/13374] loss=0.00020649042722652665\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5611/6700 83.75%\n",
      "[3m 4s] Epoch 39 [2560/13374] loss=0.0001713100318738725\n",
      "[3m 5s] Epoch 39 [5120/13374] loss=0.0001802288090402726\n",
      "[3m 6s] Epoch 39 [7680/13374] loss=0.000191685851556637\n",
      "[3m 7s] Epoch 39 [10240/13374] loss=0.00019773309250012972\n",
      "[3m 7s] Epoch 39 [12800/13374] loss=0.00019722602548426948\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5582/6700 83.31%\n",
      "[3m 9s] Epoch 40 [2560/13374] loss=0.0001611765372217633\n",
      "[3m 10s] Epoch 40 [5120/13374] loss=0.00016454209107905627\n",
      "[3m 10s] Epoch 40 [7680/13374] loss=0.0001793549847207032\n",
      "[3m 11s] Epoch 40 [10240/13374] loss=0.00019533768609107937\n",
      "[3m 13s] Epoch 40 [12800/13374] loss=0.00020492388473940083\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5616/6700 83.82%\n",
      "[3m 14s] Epoch 41 [2560/13374] loss=0.00015738687725388444\n",
      "[3m 15s] Epoch 41 [5120/13374] loss=0.00014830442232778297\n",
      "[3m 16s] Epoch 41 [7680/13374] loss=0.0001703549850693283\n",
      "[3m 17s] Epoch 41 [10240/13374] loss=0.00018795746964315186\n",
      "[3m 17s] Epoch 41 [12800/13374] loss=0.00019205927761504427\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5612/6700 83.76%\n",
      "[3m 19s] Epoch 42 [2560/13374] loss=0.0001623072566871997\n",
      "[3m 19s] Epoch 42 [5120/13374] loss=0.000166649628590676\n",
      "[3m 21s] Epoch 42 [7680/13374] loss=0.00017824589279674303\n",
      "[3m 22s] Epoch 42 [10240/13374] loss=0.00018960011766466778\n",
      "[3m 23s] Epoch 42 [12800/13374] loss=0.00019538992855814286\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5618/6700 83.85%\n",
      "[3m 24s] Epoch 43 [2560/13374] loss=0.0001650166253966745\n",
      "[3m 25s] Epoch 43 [5120/13374] loss=0.00017543103622301713\n",
      "[3m 26s] Epoch 43 [7680/13374] loss=0.00017884144848115586\n",
      "[3m 27s] Epoch 43 [10240/13374] loss=0.00018622417801452684\n",
      "[3m 27s] Epoch 43 [12800/13374] loss=0.00018943145194498358\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5600/6700 83.58%\n",
      "[3m 29s] Epoch 44 [2560/13374] loss=0.00015918480639811605\n",
      "[3m 30s] Epoch 44 [5120/13374] loss=0.00017440514639019967\n",
      "[3m 30s] Epoch 44 [7680/13374] loss=0.0001797154804080492\n",
      "[3m 31s] Epoch 44 [10240/13374] loss=0.00018348017320022337\n",
      "[3m 32s] Epoch 44 [12800/13374] loss=0.0001891678467654856\n",
      "evaluating trained model ... \n",
      "Test set: Accuracy 5594/6700 83.49%\n",
      "[3m 34s] Epoch 45 [2560/13374] loss=0.000148625598376384\n",
      "[3m 34s] Epoch 45 [5120/13374] loss=0.00016115597754833287\n",
      "[3m 35s] Epoch 45 [7680/13374] loss=0.0001656899968414412\n",
      "[3m 36s] Epoch 45 [10240/13374] loss=0.00017563707060617162\n",
      "[3m 37s] Epoch 45 [12800/13374] loss=0.00018604438184411265\n",
      "evaluating trained model ... \n"
     ]
    }
   ],
   "source": [
    "classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def trainModel():\n",
    "    def time_since(since):\n",
    "        s = time.time() - since\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainLoader, 1):\n",
    "        # print(type(names), type(countries))\n",
    "        # print(len(names), countries.shape)\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        # print(\"Shape:\", output.shape, target.shape)\n",
    "        # 注意输出和目标的维度：Shape: torch.Size([256, 18]) torch.Size([256])\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainSet)}] ', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "    return total_loss\n",
    "\n",
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testSet)\n",
    "    print(\"evaluating trained model ... \")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testLoader):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            # 注意这个keepdim的使用，为了直接和target计算loss\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            # 注意这个view_as 和 eq\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        percent = '%.2f' % (100 * correct / total) \n",
    "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "N_EPOCHS = 50\n",
    "start = time.time()\n",
    "print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "acc_list = []\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    # Train cycle\n",
    "    trainModel()\n",
    "    acc = testModel()\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1de778-8d6b-4dfd-b5e6-07403910dac1",
   "metadata": {},
   "source": [
    "5. 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfda6bfb-9d86-4c39-ace2-8a58b47a6d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:30:09.953679Z",
     "iopub.status.busy": "2024-12-17T02:30:09.953302Z",
     "iopub.status.idle": "2024-12-17T02:30:10.709466Z",
     "shell.execute_reply": "2024-12-17T02:30:10.708854Z",
     "shell.execute_reply.started": "2024-12-17T02:30:09.953656Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43macc_list\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m acc_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(acc_list)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch, acc_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_list' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "epoch = np.arange(1, len(acc_list) + 1)\n",
    "acc_list = np.array(acc_list)\n",
    "plt.plot(epoch, acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
