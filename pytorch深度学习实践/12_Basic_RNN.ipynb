{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a146de-e75a-4aed-96a3-6e1adfa99358",
   "metadata": {},
   "source": [
    "How to use RNNCell\n",
    "\n",
    "æ³¨æ„å‡ ä¸ªå‚æ•°\n",
    "\n",
    "   - è¾“å…¥å’Œéšå±‚ï¼ˆè¾“å‡ºï¼‰ç»´åº¦\n",
    "\n",
    "   - åºåˆ—é•¿åº¦\n",
    "\n",
    "   - æ‰¹å¤„ç†å¤§å°\n",
    "   \n",
    "**æ³¨ è°ƒç”¨RNNCellè¿™ä¸ªéœ€è¦å¾ªç¯ï¼Œå¾ªç¯é•¿åº¦å°±æ˜¯åºåˆ—é•¿åº¦**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97fb4e9-4fff-4b1f-86a1-8644d1f5fa17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:15:27.441120Z",
     "iopub.status.busy": "2024-12-16T14:15:27.440791Z",
     "iopub.status.idle": "2024-12-16T14:15:28.378595Z",
     "shell.execute_reply": "2024-12-16T14:15:28.378097Z",
     "shell.execute_reply.started": "2024-12-16T14:15:27.441099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "Input size: torch.Size([1, 4]) tensor([[ 1.6196, -1.6909,  0.5223, -0.2962]])\n",
      "hidden size: torch.Size([1, 2]) tensor([[0.9627, 0.9379]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.9627, 0.9379]], grad_fn=<TanhBackward0>)\n",
      "==================== 1 ====================\n",
      "Input size: torch.Size([1, 4]) tensor([[-1.0821,  1.1171,  0.4643, -1.4723]])\n",
      "hidden size: torch.Size([1, 2]) tensor([[ 0.0702, -0.1166]], grad_fn=<TanhBackward0>)\n",
      "tensor([[ 0.0702, -0.1166]], grad_fn=<TanhBackward0>)\n",
      "==================== 2 ====================\n",
      "Input size: torch.Size([1, 4]) tensor([[ 1.3373, -0.4074, -0.4094,  0.9916]])\n",
      "hidden size: torch.Size([1, 2]) tensor([[0.1573, 0.6639]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.1573, 0.6639]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1  # æ‰¹å¤„ç†å¤§å°\n",
    "seq_len = 3     # åºåˆ—é•¿åº¦\n",
    "input_size = 4  # è¾“å…¥ç»´åº¦\n",
    "hidden_size = 2 # éšå±‚ç»´åº¦\n",
    "\n",
    "cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "# (seq, batch, features)\n",
    "dataset = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(batch_size, hidden_size)\n",
    "\n",
    "# è¿™ä¸ªå¾ªç¯å°±æ˜¯å¤„ç†seq_lené•¿åº¦çš„æ•°æ®\n",
    "for idx, data in enumerate(dataset):\n",
    "    print('=' * 20, idx, '=' * 20)\n",
    "    print('Input size:', data.shape, data)\n",
    "\n",
    "    hidden = cell(data, hidden)\n",
    "\n",
    "    print('hidden size:', hidden.shape, hidden)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14c28a-9b2b-434b-bc3f-4563da79b53d",
   "metadata": {},
   "source": [
    "How to use RNN\n",
    "\n",
    "ç¡®å®šå‡ ä¸ªå‚æ•°\n",
    "\n",
    "    1.input_sizeå’Œhidden_size: è¾“å…¥ç»´åº¦å’Œéšå±‚ç»´åº¦\n",
    "\n",
    "    2.batch_size: æ‰¹å¤„ç†å¤§å°\n",
    "\n",
    "    3.seq_len: åºåˆ—é•¿åº¦\n",
    "\n",
    "    4.num_layers: éšå±‚æ•°ç›®\n",
    "\n",
    "æ³¨: **ç›´æ¥è°ƒç”¨RNNè¿™ä¸ªä¸ç”¨å¾ªç¯**\n",
    "\n",
    "æ³¨ï¼š**å¦‚æœä½¿ç”¨batch_first: if True, the input and output tensors are provided as:(batch_size, seq_len, input_size)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55892b70-5b96-4415-9d56-9462e3ccf09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:19:01.315235Z",
     "iopub.status.busy": "2024-12-16T14:19:01.314811Z",
     "iopub.status.idle": "2024-12-16T14:19:01.321642Z",
     "shell.execute_reply": "2024-12-16T14:19:01.321094Z",
     "shell.execute_reply.started": "2024-12-16T14:19:01.315214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([3, 1, 2])\n",
      "Output: tensor([[[ 0.0775, -0.1708]],\n",
      "\n",
      "        [[-0.8887, -0.7974]],\n",
      "\n",
      "        [[ 0.6106, -0.3915]]], grad_fn=<StackBackward0>)\n",
      "Hidden size: torch.Size([1, 1, 2])\n",
      "Hidden: tensor([[[ 0.6106, -0.3915]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "# (seqLen, batchSize, inputSize)\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "out, hidden = cell(inputs, hidden)\n",
    "\n",
    "print('Output size:', out.shape)        # (seq_len, batch_size, hidden_size)\n",
    "print('Output:', out)\n",
    "print('Hidden size:', hidden.shape)     # (num_layers, batch_size, hidden_size)\n",
    "print('Hidden:', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741d06e-b13f-4def-a368-62b8be1ad0b4",
   "metadata": {},
   "source": [
    "Example: Using RNNCell\n",
    "\n",
    "Hello --> ohlol\n",
    "\n",
    "    1.é¦–å…ˆéœ€è¦å°†è¾“å…¥çš„å•è¯è½¬æˆå‘é‡one-hot vector\n",
    "\n",
    "    2.æ³¨æ„input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc09de-f425-4ec6-a7ab-651cc73de68c",
   "metadata": {},
   "source": [
    "æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f21538-84e5-4590-aa4c-e27dd3be2666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:21:04.017741Z",
     "iopub.status.busy": "2024-12-16T14:21:04.017404Z",
     "iopub.status.idle": "2024-12-16T14:21:04.022644Z",
     "shell.execute_reply": "2024-12-16T14:21:04.022198Z",
     "shell.execute_reply.started": "2024-12-16T14:21:04.017721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 3, 3]    # helloä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "y_data = [3, 1, 2, 3, 2]    # ohlolä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data] # (seqLen, inputSize)\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)   # torch.Tensoré»˜è®¤æ˜¯torch.FloatTensoræ˜¯32ä½æµ®ç‚¹ç±»å‹æ•°æ®ï¼Œtorch.LongTensoræ˜¯64ä½æ•´å‹\n",
    "print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8848da-b155-47ba-805b-c7ce71b4d114",
   "metadata": {},
   "source": [
    "æ„å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e13b2a-11a5-4b31-988a-b5468938eb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:21:34.762746Z",
     "iopub.status.busy": "2024-12-16T14:21:34.762408Z",
     "iopub.status.idle": "2024-12-16T14:21:35.333405Z",
     "shell.execute_reply": "2024-12-16T14:21:35.332866Z",
     "shell.execute_reply.started": "2024-12-16T14:21:34.762715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        hidden = self.rnncell(inputs, hidden)   # (batch_size, hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3a646-8779-4ead-b52e-7e0cdc596e90",
   "metadata": {},
   "source": [
    "è®­ç»ƒæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a9d099-4b4f-4222-a8af-c36944ca04a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:22:07.466420Z",
     "iopub.status.busy": "2024-12-16T14:22:07.466026Z",
     "iopub.status.idle": "2024-12-16T14:22:07.490173Z",
     "shell.execute_reply": "2024-12-16T14:22:07.489705Z",
     "shell.execute_reply.started": "2024-12-16T14:22:07.466400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:loooo, Epoch [1/15] loss=6.5885\n",
      "Predicted string:lllll, Epoch [2/15] loss=6.1335\n",
      "Predicted string:lllll, Epoch [3/15] loss=5.6965\n",
      "Predicted string:ollll, Epoch [4/15] loss=5.1592\n",
      "Predicted string:oolll, Epoch [5/15] loss=4.7770\n",
      "Predicted string:ooloo, Epoch [6/15] loss=4.4947\n",
      "Predicted string:ooloo, Epoch [7/15] loss=4.2295\n",
      "Predicted string:ohloo, Epoch [8/15] loss=4.0044\n",
      "Predicted string:ohloo, Epoch [9/15] loss=3.8305\n",
      "Predicted string:ohloo, Epoch [10/15] loss=3.6638\n",
      "Predicted string:ohloo, Epoch [11/15] loss=3.4557\n",
      "Predicted string:ohloo, Epoch [12/15] loss=3.2129\n",
      "Predicted string:ohloo, Epoch [13/15] loss=2.9912\n",
      "Predicted string:ohlol, Epoch [14/15] loss=2.8103\n",
      "Predicted string:ohlol, Epoch [15/15] loss=2.6490\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print('Predicted string:', end='')\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = net(input, hidden)\n",
    "        # æ³¨æ„äº¤å‰ç†µåœ¨è®¡ç®—lossçš„æ—¶å€™ç»´åº¦å…³ç³»ï¼Œè¿™é‡Œçš„hiddenæ˜¯([1, 4]), labelæ˜¯ ([1])\n",
    "        loss += criterion(hidden, label)\n",
    "        _, idx = hidden.max(dim = 1)\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd622d89-f2cf-4f97-8dbc-0fcb5af5a9e8",
   "metadata": {},
   "source": [
    "Example: Using RNN\n",
    "\n",
    "æ³¨æ„inputså’Œlabelsçš„ç»´åº¦\n",
    "\n",
    "    inputsç»´åº¦æ˜¯: (seqLen, batch_size, input_size)\n",
    "\n",
    "    labelsç»´åº¦æ˜¯: (seqLen * batch_size)\n",
    "\n",
    "æ³¨æ„outputsç»´åº¦ï¼Œå¯¹åº”å’Œlabelsåšäº¤å‰ç†µçš„ç»´åº¦\n",
    "\n",
    "    outputsç»´åº¦æ˜¯: (seqLen, batch_size, hidden_size)\n",
    "\n",
    "    ä¸ºäº†èƒ½å’Œlabelsåšäº¤å‰ç†µï¼Œéœ€è¦reshapeä¸€ä¸‹: outputs.view(-1, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad1c64-05d1-44bd-925c-ca2c8989a18c",
   "metadata": {},
   "source": [
    "æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fa955f-dbab-44ed-8d6c-f60f05f19aeb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-17T02:01:01.813614Z",
     "iopub.status.busy": "2024-12-17T02:01:01.813112Z",
     "iopub.status.idle": "2024-12-17T02:01:02.949317Z",
     "shell.execute_reply": "2024-12-17T02:01:02.948784Z",
     "shell.execute_reply.started": "2024-12-17T02:01:01.813574Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "num_layers = 1\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 3, 3]    # helloä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "y_data = [3, 1, 2, 3, 2]    # ohlolä¸­å„ä¸ªå­—ç¬¦çš„ä¸‹æ ‡\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]  # (seqLen, inputSize)\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data)\n",
    "print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f62f08-b96c-4377-a2f6-0304e3dec77b",
   "metadata": {},
   "source": [
    "æ„å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2185d28-60d8-4035-9546-40b286b1cd15",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-17T02:02:40.408459Z",
     "iopub.status.busy": "2024-12-17T02:02:40.408013Z",
     "iopub.status.idle": "2024-12-17T02:02:40.414068Z",
     "shell.execute_reply": "2024-12-17T02:02:40.413587Z",
     "shell.execute_reply.started": "2024-12-17T02:02:40.408430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        out, _ = self.rnn(inputs, hidden)       # æ³¨æ„ç»´åº¦æ˜¯(seqLen, batch_size, hidden_size)\n",
    "        return out.view(-1, self.hidden_size)     # ä¸ºäº†å®¹æ˜“è®¡ç®—äº¤å‰ç†µè¿™é‡Œè°ƒæ•´ç»´åº¦ä¸º(seqLen * batch_size, hidden_size)\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96796239-3495-407d-a0da-a5f1f223800d",
   "metadata": {},
   "source": [
    "è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51460b4a-f228-4183-a688-223faa886c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:04:31.244279Z",
     "iopub.status.busy": "2024-12-17T02:04:31.243953Z",
     "iopub.status.idle": "2024-12-17T02:04:34.999248Z",
     "shell.execute_reply": "2024-12-17T02:04:34.998568Z",
     "shell.execute_reply.started": "2024-12-17T02:04:31.244259Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  lhhhh, Epoch [1/15] loss = 1.443\n",
      "Predicted:  lhlol, Epoch [2/15] loss = 1.149\n",
      "Predicted:  lhlol, Epoch [3/15] loss = 1.000\n",
      "Predicted:  lhlol, Epoch [4/15] loss = 0.857\n",
      "Predicted:  ohlol, Epoch [5/15] loss = 0.733\n",
      "Predicted:  ohlol, Epoch [6/15] loss = 0.667\n",
      "Predicted:  ohlol, Epoch [7/15] loss = 0.617\n",
      "Predicted:  ohlol, Epoch [8/15] loss = 0.571\n",
      "Predicted:  ohlol, Epoch [9/15] loss = 0.528\n",
      "Predicted:  ohlol, Epoch [10/15] loss = 0.495\n",
      "Predicted:  ohlol, Epoch [11/15] loss = 0.480\n",
      "Predicted:  ohlol, Epoch [12/15] loss = 0.467\n",
      "Predicted:  ohlol, Epoch [13/15] loss = 0.446\n",
      "Predicted:  ohlol, Epoch [14/15] loss = 0.426\n",
      "Predicted:  ohlol, Epoch [15/15] loss = 0.415\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    # print(outputs.shape, labels.shape)\n",
    "    # è¿™é‡Œçš„outputsç»´åº¦æ˜¯([seqLen * batch_size, hidden]), labelsç»´åº¦æ˜¯([seqLen])\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6510339-d772-4c5d-980f-6519d5a6314c",
   "metadata": {},
   "source": [
    "å°†ä¸€ä¸ªå•è¯å˜æˆvector\n",
    "\n",
    "One-hot encoding of words and characters\n",
    "\n",
    "one-hot vectors high-dimension --> lower-dimension\n",
    "\n",
    "one-hot vectors sparse --> dense\n",
    "\n",
    "one-hot vectors hardcoded --> learn from data\n",
    "\n",
    "Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2bc11-0488-4001-9898-769c5ce05de7",
   "metadata": {},
   "source": [
    "æ„å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0e0347-2f98-4c0a-b82b-65e7d9bd2c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T02:17:50.555273Z",
     "iopub.status.busy": "2024-12-17T02:17:50.554915Z",
     "iopub.status.idle": "2024-12-17T02:17:50.561545Z",
     "shell.execute_reply": "2024-12-17T02:17:50.561013Z",
     "shell.execute_reply.started": "2024-12-17T02:17:50.555251Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# parameters\n",
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        x = self.emb(x)                 # (batch, seqLen, embeddingSize)\n",
    "        x, _ = self.rnn(x, hidden)      # è¾“å‡º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, hidden_size)\n",
    "        x = self.fc(x)                  # è¾“å‡º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’ğ’–ğ’ğ‘ªğ’ğ’‚ğ’”ğ’”)\n",
    "        return x.view(-1, num_class)    # reshape to use Cross Entropy: (ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†Ã—ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’ğ’–ğ’ğ‘ªğ’ğ’‚ğ’”ğ’”)\n",
    "\n",
    "\n",
    "net = Model()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57ce96-ba7e-4253-b36a-80ae53b74eed",
   "metadata": {},
   "source": [
    "å‡†å¤‡æ•°æ®å¹¶è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13998d73-8aa5-46e9-b8b3-8045735e05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [[1, 0, 2, 2, 3]]  # (batch, seq_len)\n",
    "y_data = [3, 1, 2, 3, 2]    # (batch * seq_len)\n",
    "\n",
    "inputs = torch.LongTensor(x_data)   # Input should be LongTensor: (batchSize, seqLen)\n",
    "labels = torch.LongTensor(y_data)   # Target should be LongTensor: (batchSize * seqLen)\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs) \n",
    "    loss = criterion(outputs, labels) \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1) \n",
    "    idx = idx.data.numpy() \n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
