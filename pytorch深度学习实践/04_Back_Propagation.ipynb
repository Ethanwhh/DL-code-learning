{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc8854e-8998-4a16-9de3-232fa352775d",
   "metadata": {},
   "source": [
    "w是Tensor(张量类型)，Tensor中包含data和grad，data和grad也是Tensor。grad初始为None，调用l.backward()方法后w.grad为Tensor，故更新w.data时需使用w.grad.data。如果w需要计算梯度，那构建的计算图中，跟w相关的tensor都默认需要计算梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78832a7b-eecb-44bb-95ac-839bf9e8e823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:43:59.933952Z",
     "iopub.status.busy": "2024-12-10T01:43:59.933561Z",
     "iopub.status.idle": "2024-12-10T01:43:59.938612Z",
     "shell.execute_reply": "2024-12-10T01:43:59.938158Z",
     "shell.execute_reply.started": "2024-12-10T01:43:59.933932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n",
      "tensor([1.])\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1.0])\n",
    "a.requires_grad = True      # 或者 a.requires_grad_()\n",
    "print(a)\n",
    "print(a.data)\n",
    "print(a.type())             # a的类型是tensor\n",
    "print(a.data.type())        # a.data的类型是tensor\n",
    "print(a.grad)\n",
    "print(type(a.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e29137-de3c-45c9-8148-684f24f2b536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T01:46:19.936837Z",
     "iopub.status.busy": "2024-12-10T01:46:19.936494Z",
     "iopub.status.idle": "2024-12-10T01:46:19.975166Z",
     "shell.execute_reply": "2024-12-10T01:46:19.974671Z",
     "shell.execute_reply.started": "2024-12-10T01:46:19.936817Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0\n",
      "\tgrad: 1.0 2.0 -2.0\n",
      "\tgrad: 2.0 4.0 -7.840000152587891\n",
      "\tgrad: 3.0 6.0 -16.228801727294922\n",
      "progress: 0 7.315943717956543\n",
      "\tgrad: 1.0 2.0 -1.478623867034912\n",
      "\tgrad: 2.0 4.0 -5.796205520629883\n",
      "\tgrad: 3.0 6.0 -11.998146057128906\n",
      "progress: 1 3.9987640380859375\n",
      "\tgrad: 1.0 2.0 -1.0931644439697266\n",
      "\tgrad: 2.0 4.0 -4.285204887390137\n",
      "\tgrad: 3.0 6.0 -8.870372772216797\n",
      "progress: 2 2.1856532096862793\n",
      "\tgrad: 1.0 2.0 -0.8081896305084229\n",
      "\tgrad: 2.0 4.0 -3.1681032180786133\n",
      "\tgrad: 3.0 6.0 -6.557973861694336\n",
      "progress: 3 1.1946394443511963\n",
      "\tgrad: 1.0 2.0 -0.5975041389465332\n",
      "\tgrad: 2.0 4.0 -2.3422164916992188\n",
      "\tgrad: 3.0 6.0 -4.848389625549316\n",
      "progress: 4 0.6529689431190491\n",
      "\tgrad: 1.0 2.0 -0.4417421817779541\n",
      "\tgrad: 2.0 4.0 -1.7316293716430664\n",
      "\tgrad: 3.0 6.0 -3.58447265625\n",
      "progress: 5 0.35690122842788696\n",
      "\tgrad: 1.0 2.0 -0.3265852928161621\n",
      "\tgrad: 2.0 4.0 -1.2802143096923828\n",
      "\tgrad: 3.0 6.0 -2.650045394897461\n",
      "progress: 6 0.195076122879982\n",
      "\tgrad: 1.0 2.0 -0.24144840240478516\n",
      "\tgrad: 2.0 4.0 -0.9464778900146484\n",
      "\tgrad: 3.0 6.0 -1.9592113494873047\n",
      "progress: 7 0.10662525147199631\n",
      "\tgrad: 1.0 2.0 -0.17850565910339355\n",
      "\tgrad: 2.0 4.0 -0.699742317199707\n",
      "\tgrad: 3.0 6.0 -1.4484672546386719\n",
      "progress: 8 0.0582793727517128\n",
      "\tgrad: 1.0 2.0 -0.1319713592529297\n",
      "\tgrad: 2.0 4.0 -0.5173273086547852\n",
      "\tgrad: 3.0 6.0 -1.070866584777832\n",
      "progress: 9 0.03185431286692619\n",
      "\tgrad: 1.0 2.0 -0.09756779670715332\n",
      "\tgrad: 2.0 4.0 -0.3824653625488281\n",
      "\tgrad: 3.0 6.0 -0.7917022705078125\n",
      "progress: 10 0.017410902306437492\n",
      "\tgrad: 1.0 2.0 -0.07213282585144043\n",
      "\tgrad: 2.0 4.0 -0.2827606201171875\n",
      "\tgrad: 3.0 6.0 -0.5853137969970703\n",
      "progress: 11 0.009516451507806778\n",
      "\tgrad: 1.0 2.0 -0.053328514099121094\n",
      "\tgrad: 2.0 4.0 -0.2090473175048828\n",
      "\tgrad: 3.0 6.0 -0.43272972106933594\n",
      "progress: 12 0.005201528314501047\n",
      "\tgrad: 1.0 2.0 -0.039426326751708984\n",
      "\tgrad: 2.0 4.0 -0.15455150604248047\n",
      "\tgrad: 3.0 6.0 -0.3199195861816406\n",
      "progress: 13 0.0028430151287466288\n",
      "\tgrad: 1.0 2.0 -0.029148340225219727\n",
      "\tgrad: 2.0 4.0 -0.11426162719726562\n",
      "\tgrad: 3.0 6.0 -0.23652076721191406\n",
      "progress: 14 0.0015539465239271522\n",
      "\tgrad: 1.0 2.0 -0.021549701690673828\n",
      "\tgrad: 2.0 4.0 -0.08447456359863281\n",
      "\tgrad: 3.0 6.0 -0.17486286163330078\n",
      "progress: 15 0.0008493617060594261\n",
      "\tgrad: 1.0 2.0 -0.01593184471130371\n",
      "\tgrad: 2.0 4.0 -0.062453269958496094\n",
      "\tgrad: 3.0 6.0 -0.12927818298339844\n",
      "progress: 16 0.00046424579340964556\n",
      "\tgrad: 1.0 2.0 -0.011778593063354492\n",
      "\tgrad: 2.0 4.0 -0.046172142028808594\n",
      "\tgrad: 3.0 6.0 -0.09557533264160156\n",
      "progress: 17 0.0002537401160225272\n",
      "\tgrad: 1.0 2.0 -0.00870823860168457\n",
      "\tgrad: 2.0 4.0 -0.03413581848144531\n",
      "\tgrad: 3.0 6.0 -0.07066154479980469\n",
      "progress: 18 0.00013869594840798527\n",
      "\tgrad: 1.0 2.0 -0.006437778472900391\n",
      "\tgrad: 2.0 4.0 -0.025236129760742188\n",
      "\tgrad: 3.0 6.0 -0.052239418029785156\n",
      "progress: 19 7.580435340059921e-05\n",
      "\tgrad: 1.0 2.0 -0.004759550094604492\n",
      "\tgrad: 2.0 4.0 -0.018657684326171875\n",
      "\tgrad: 3.0 6.0 -0.038620948791503906\n",
      "progress: 20 4.143271507928148e-05\n",
      "\tgrad: 1.0 2.0 -0.003518819808959961\n",
      "\tgrad: 2.0 4.0 -0.0137939453125\n",
      "\tgrad: 3.0 6.0 -0.028553009033203125\n",
      "progress: 21 2.264650902361609e-05\n",
      "\tgrad: 1.0 2.0 -0.00260162353515625\n",
      "\tgrad: 2.0 4.0 -0.010198593139648438\n",
      "\tgrad: 3.0 6.0 -0.021108627319335938\n",
      "progress: 22 1.2377059647405986e-05\n",
      "\tgrad: 1.0 2.0 -0.0019233226776123047\n",
      "\tgrad: 2.0 4.0 -0.0075397491455078125\n",
      "\tgrad: 3.0 6.0 -0.0156097412109375\n",
      "progress: 23 6.768445018678904e-06\n",
      "\tgrad: 1.0 2.0 -0.0014221668243408203\n",
      "\tgrad: 2.0 4.0 -0.0055751800537109375\n",
      "\tgrad: 3.0 6.0 -0.011541366577148438\n",
      "progress: 24 3.7000872907810844e-06\n",
      "\tgrad: 1.0 2.0 -0.0010514259338378906\n",
      "\tgrad: 2.0 4.0 -0.0041217803955078125\n",
      "\tgrad: 3.0 6.0 -0.008531570434570312\n",
      "progress: 25 2.021880391112063e-06\n",
      "\tgrad: 1.0 2.0 -0.0007772445678710938\n",
      "\tgrad: 2.0 4.0 -0.0030469894409179688\n",
      "\tgrad: 3.0 6.0 -0.006305694580078125\n",
      "progress: 26 1.1044940038118511e-06\n",
      "\tgrad: 1.0 2.0 -0.0005745887756347656\n",
      "\tgrad: 2.0 4.0 -0.0022525787353515625\n",
      "\tgrad: 3.0 6.0 -0.0046634674072265625\n",
      "progress: 27 6.041091182851233e-07\n",
      "\tgrad: 1.0 2.0 -0.0004248619079589844\n",
      "\tgrad: 2.0 4.0 -0.0016651153564453125\n",
      "\tgrad: 3.0 6.0 -0.003444671630859375\n",
      "progress: 28 3.296045179013163e-07\n",
      "\tgrad: 1.0 2.0 -0.0003139972686767578\n",
      "\tgrad: 2.0 4.0 -0.0012311935424804688\n",
      "\tgrad: 3.0 6.0 -0.0025491714477539062\n",
      "progress: 29 1.805076408345485e-07\n",
      "\tgrad: 1.0 2.0 -0.00023221969604492188\n",
      "\tgrad: 2.0 4.0 -0.0009107589721679688\n",
      "\tgrad: 3.0 6.0 -0.0018854141235351562\n",
      "progress: 30 9.874406714516226e-08\n",
      "\tgrad: 1.0 2.0 -0.00017189979553222656\n",
      "\tgrad: 2.0 4.0 -0.0006742477416992188\n",
      "\tgrad: 3.0 6.0 -0.00139617919921875\n",
      "progress: 31 5.4147676564753056e-08\n",
      "\tgrad: 1.0 2.0 -0.0001270771026611328\n",
      "\tgrad: 2.0 4.0 -0.0004978179931640625\n",
      "\tgrad: 3.0 6.0 -0.00102996826171875\n",
      "progress: 32 2.9467628337442875e-08\n",
      "\tgrad: 1.0 2.0 -9.393692016601562e-05\n",
      "\tgrad: 2.0 4.0 -0.0003681182861328125\n",
      "\tgrad: 3.0 6.0 -0.0007610321044921875\n",
      "progress: 33 1.6088051779661328e-08\n",
      "\tgrad: 1.0 2.0 -6.937980651855469e-05\n",
      "\tgrad: 2.0 4.0 -0.00027179718017578125\n",
      "\tgrad: 3.0 6.0 -0.000560760498046875\n",
      "progress: 34 8.734787115827203e-09\n",
      "\tgrad: 1.0 2.0 -5.125999450683594e-05\n",
      "\tgrad: 2.0 4.0 -0.00020122528076171875\n",
      "\tgrad: 3.0 6.0 -0.0004177093505859375\n",
      "progress: 35 4.8466972657479346e-09\n",
      "\tgrad: 1.0 2.0 -3.790855407714844e-05\n",
      "\tgrad: 2.0 4.0 -0.000148773193359375\n",
      "\tgrad: 3.0 6.0 -0.000308990478515625\n",
      "progress: 36 2.6520865503698587e-09\n",
      "\tgrad: 1.0 2.0 -2.8133392333984375e-05\n",
      "\tgrad: 2.0 4.0 -0.000110626220703125\n",
      "\tgrad: 3.0 6.0 -0.0002288818359375\n",
      "progress: 37 1.4551915228366852e-09\n",
      "\tgrad: 1.0 2.0 -2.09808349609375e-05\n",
      "\tgrad: 2.0 4.0 -8.20159912109375e-05\n",
      "\tgrad: 3.0 6.0 -0.00016880035400390625\n",
      "progress: 38 7.914877642178908e-10\n",
      "\tgrad: 1.0 2.0 -1.5497207641601562e-05\n",
      "\tgrad: 2.0 4.0 -6.103515625e-05\n",
      "\tgrad: 3.0 6.0 -0.000125885009765625\n",
      "progress: 39 4.4019543565809727e-10\n",
      "\tgrad: 1.0 2.0 -1.1444091796875e-05\n",
      "\tgrad: 2.0 4.0 -4.482269287109375e-05\n",
      "\tgrad: 3.0 6.0 -9.1552734375e-05\n",
      "progress: 40 2.3283064365386963e-10\n",
      "\tgrad: 1.0 2.0 -8.344650268554688e-06\n",
      "\tgrad: 2.0 4.0 -3.24249267578125e-05\n",
      "\tgrad: 3.0 6.0 -6.580352783203125e-05\n",
      "progress: 41 1.2028067430946976e-10\n",
      "\tgrad: 1.0 2.0 -5.9604644775390625e-06\n",
      "\tgrad: 2.0 4.0 -2.288818359375e-05\n",
      "\tgrad: 3.0 6.0 -4.57763671875e-05\n",
      "progress: 42 5.820766091346741e-11\n",
      "\tgrad: 1.0 2.0 -4.291534423828125e-06\n",
      "\tgrad: 2.0 4.0 -1.71661376953125e-05\n",
      "\tgrad: 3.0 6.0 -3.719329833984375e-05\n",
      "progress: 43 3.842615114990622e-11\n",
      "\tgrad: 1.0 2.0 -3.337860107421875e-06\n",
      "\tgrad: 2.0 4.0 -1.33514404296875e-05\n",
      "\tgrad: 3.0 6.0 -2.86102294921875e-05\n",
      "progress: 44 2.2737367544323206e-11\n",
      "\tgrad: 1.0 2.0 -2.6226043701171875e-06\n",
      "\tgrad: 2.0 4.0 -1.049041748046875e-05\n",
      "\tgrad: 3.0 6.0 -2.288818359375e-05\n",
      "progress: 45 1.4551915228366852e-11\n",
      "\tgrad: 1.0 2.0 -1.9073486328125e-06\n",
      "\tgrad: 2.0 4.0 -7.62939453125e-06\n",
      "\tgrad: 3.0 6.0 -1.430511474609375e-05\n",
      "progress: 46 5.6843418860808015e-12\n",
      "\tgrad: 1.0 2.0 -1.430511474609375e-06\n",
      "\tgrad: 2.0 4.0 -5.7220458984375e-06\n",
      "\tgrad: 3.0 6.0 -1.1444091796875e-05\n",
      "progress: 47 3.637978807091713e-12\n",
      "\tgrad: 1.0 2.0 -1.1920928955078125e-06\n",
      "\tgrad: 2.0 4.0 -4.76837158203125e-06\n",
      "\tgrad: 3.0 6.0 -1.1444091796875e-05\n",
      "progress: 48 3.637978807091713e-12\n",
      "\tgrad: 1.0 2.0 -9.5367431640625e-07\n",
      "\tgrad: 2.0 4.0 -3.814697265625e-06\n",
      "\tgrad: 3.0 6.0 -8.58306884765625e-06\n",
      "progress: 49 2.0463630789890885e-12\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 50 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 51 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 52 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 53 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 54 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 55 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 56 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 57 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 58 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 59 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 60 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 61 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 62 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 63 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 64 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 65 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 66 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 67 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 68 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 69 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 70 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 71 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 72 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 73 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 74 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 75 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 76 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 77 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 78 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 79 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 80 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 81 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 82 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 83 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 84 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 85 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 86 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 87 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 88 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 89 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 90 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 91 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 92 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 93 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 94 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 95 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 96 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 97 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 98 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 99 9.094947017729282e-13\n",
      "predict (after training) 4 7.999998569488525\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = torch.tensor([1.0])   # w的初值为1.0\n",
    "w.requires_grad = True    # 需要计算梯度\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    return x*w  # w是一个Tensor\n",
    "\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)**2\n",
    "\n",
    "print(\"predict (before training)\", 4, forward(4).item())\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        l =loss(x,y)       # l是一个张量，tensor主要是在建立计算图 forward, compute the loss\n",
    "        l.backward()       # backward,compute grad for Tensor whose requires_grad set to True\n",
    "        print('\\tgrad:', x, y, w.grad.item())\n",
    "        w.data = w.data - 0.01 * w.grad.data   # 权重更新时，注意grad也是一个tensor\n",
    "\n",
    "        w.grad.data.zero_()       # after update, remember set the grad to zero\n",
    "\n",
    "    print('progress:', epoch, l.item())      # 取出loss使用l.item，不要直接使用l（l是tensor会构建计算图）\n",
    "\n",
    "print(\"predict (after training)\", 4, forward(4).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd5ad3-027d-48d6-ae96-7abf60a09e0b",
   "metadata": {},
   "source": [
    "画出二次模型y=w1x²+w2x+b，损失函数loss=(ŷ-y)²的计算图，并且手动推导反向传播的过程，最后用pytorch的代码实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81639f6f-8214-43f7-a136-ca027a9cef32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T02:01:09.132354Z",
     "iopub.status.busy": "2024-12-10T02:01:09.132037Z",
     "iopub.status.idle": "2024-12-10T02:01:10.724634Z",
     "shell.execute_reply": "2024-12-10T02:01:10.724111Z",
     "shell.execute_reply.started": "2024-12-10T02:01:09.132334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict (befortraining) 4 tensor([21.], grad_fn=<AddBackward0>)\n",
      "\tgrad: 1.0 2.0 2.0 2.0 2.0\n",
      "\tgrad: 2.0 4.0 22.880001068115234 11.440000534057617 5.720000267028809\n",
      "\tgrad: 3.0 6.0 77.04720306396484 25.682401657104492 8.560800552368164\n",
      "Epoch: 0 18.321826934814453\n",
      "\tgrad: 1.0 2.0 -1.1466078758239746 -1.1466078758239746 -1.1466078758239746\n",
      "\tgrad: 2.0 4.0 -15.536651611328125 -7.7683258056640625 -3.8841629028320312\n",
      "\tgrad: 3.0 6.0 -30.432214736938477 -10.144071578979492 -3.381357192993164\n",
      "Epoch: 1 2.858394145965576\n",
      "\tgrad: 1.0 2.0 0.3451242446899414 0.3451242446899414 0.3451242446899414\n",
      "\tgrad: 2.0 4.0 2.4273414611816406 1.2136707305908203 0.6068353652954102\n",
      "\tgrad: 3.0 6.0 19.449920654296875 6.483306884765625 2.161102294921875\n",
      "Epoch: 2 1.1675907373428345\n",
      "\tgrad: 1.0 2.0 -0.32242679595947266 -0.32242679595947266 -0.32242679595947266\n",
      "\tgrad: 2.0 4.0 -5.845773696899414 -2.922886848449707 -1.4614434242248535\n",
      "\tgrad: 3.0 6.0 -3.8828859329223633 -1.294295310974121 -0.43143177032470703\n",
      "Epoch: 3 0.04653334245085716\n",
      "\tgrad: 1.0 2.0 0.01369333267211914 0.01369333267211914 0.01369333267211914\n",
      "\tgrad: 2.0 4.0 -1.9140911102294922 -0.9570455551147461 -0.47852277755737305\n",
      "\tgrad: 3.0 6.0 6.855700492858887 2.285233497619629 0.761744499206543\n",
      "Epoch: 4 0.14506366848945618\n",
      "\tgrad: 1.0 2.0 -0.11818885803222656 -0.11818885803222656 -0.11818885803222656\n",
      "\tgrad: 2.0 4.0 -3.664388656616211 -1.8321943283081055 -0.9160971641540527\n",
      "\tgrad: 3.0 6.0 1.7454700469970703 0.5818233489990234 0.1939411163330078\n",
      "Epoch: 5 0.009403289295732975\n",
      "\tgrad: 1.0 2.0 -0.03326845169067383 -0.03326845169067383 -0.03326845169067383\n",
      "\tgrad: 2.0 4.0 -2.7738723754882812 -1.3869361877441406 -0.6934680938720703\n",
      "\tgrad: 3.0 6.0 4.014009475708008 1.338003158569336 0.4460010528564453\n",
      "Epoch: 6 0.04972923547029495\n",
      "\tgrad: 1.0 2.0 -0.050147056579589844 -0.050147056579589844 -0.050147056579589844\n",
      "\tgrad: 2.0 4.0 -3.1150074005126953 -1.5575037002563477 -0.7787518501281738\n",
      "\tgrad: 3.0 6.0 2.8533897399902344 0.9511299133300781 0.3170433044433594\n",
      "Epoch: 7 0.025129113346338272\n",
      "\tgrad: 1.0 2.0 -0.020544052124023438 -0.020544052124023438 -0.020544052124023438\n",
      "\tgrad: 2.0 4.0 -2.8858280181884766 -1.4429140090942383 -0.7214570045471191\n",
      "\tgrad: 3.0 6.0 3.292379379272461 1.0974597930908203 0.36581993103027344\n",
      "Epoch: 8 0.03345605731010437\n",
      "\tgrad: 1.0 2.0 -0.013420581817626953 -0.013420581817626953 -0.013420581817626953\n",
      "\tgrad: 2.0 4.0 -2.9246826171875 -1.46234130859375 -0.731170654296875\n",
      "\tgrad: 3.0 6.0 2.990907669067383 0.9969692230224609 0.3323230743408203\n",
      "Epoch: 9 0.027609655633568764\n",
      "\tgrad: 1.0 2.0 0.0033445358276367188 0.0033445358276367188 0.0033445358276367188\n",
      "\tgrad: 2.0 4.0 -2.841381072998047 -1.4206905364990234 -0.7103452682495117\n",
      "\tgrad: 3.0 6.0 3.0377025604248047 1.0125675201416016 0.3375225067138672\n",
      "Epoch: 10 0.02848036028444767\n",
      "\tgrad: 1.0 2.0 0.014836311340332031 0.014836311340332031 0.014836311340332031\n",
      "\tgrad: 2.0 4.0 -2.8173885345458984 -1.4086942672729492 -0.7043471336364746\n",
      "\tgrad: 3.0 6.0 2.9260196685791016 0.9753398895263672 0.32511329650878906\n",
      "Epoch: 11 0.02642466314136982\n",
      "\tgrad: 1.0 2.0 0.028025150299072266 0.028025150299072266 0.028025150299072266\n",
      "\tgrad: 2.0 4.0 -2.768169403076172 -1.384084701538086 -0.692042350769043\n",
      "\tgrad: 3.0 6.0 2.891498565673828 0.9638328552246094 0.3212776184082031\n",
      "Epoch: 12 0.025804826989769936\n",
      "\tgrad: 1.0 2.0 0.03969764709472656 0.03969764709472656 0.03969764709472656\n",
      "\tgrad: 2.0 4.0 -2.732961654663086 -1.366480827331543 -0.6832404136657715\n",
      "\tgrad: 3.0 6.0 2.8243446350097656 0.9414482116699219 0.3138160705566406\n",
      "Epoch: 13 0.02462013065814972\n",
      "\tgrad: 1.0 2.0 0.051377296447753906 0.051377296447753906 0.051377296447753906\n",
      "\tgrad: 2.0 4.0 -2.6934165954589844 -1.3467082977294922 -0.6733541488647461\n",
      "\tgrad: 3.0 6.0 2.7755842208862305 0.9251947402954102 0.3083982467651367\n",
      "Epoch: 14 0.023777369409799576\n",
      "\tgrad: 1.0 2.0 0.062380313873291016 0.062380313873291016 0.062380313873291016\n",
      "\tgrad: 2.0 4.0 -2.6580047607421875 -1.3290023803710938 -0.6645011901855469\n",
      "\tgrad: 3.0 6.0 2.7212963104248047 0.9070987701416016 0.3023662567138672\n",
      "Epoch: 15 0.0228563379496336\n",
      "\tgrad: 1.0 2.0 0.07305240631103516 0.07305240631103516 0.07305240631103516\n",
      "\tgrad: 2.0 4.0 -2.622692108154297 -1.3113460540771484 -0.6556730270385742\n",
      "\tgrad: 3.0 6.0 2.672501564025879 0.890833854675293 0.29694461822509766\n",
      "Epoch: 16 0.022044027224183083\n",
      "\tgrad: 1.0 2.0 0.08325767517089844 0.08325767517089844 0.08325767517089844\n",
      "\tgrad: 2.0 4.0 -2.589275360107422 -1.294637680053711 -0.6473188400268555\n",
      "\tgrad: 3.0 6.0 2.6239728927612305 0.8746576309204102 0.2915525436401367\n",
      "Epoch: 17 0.02125072106719017\n",
      "\tgrad: 1.0 2.0 0.09308338165283203 0.09308338165283203 0.09308338165283203\n",
      "\tgrad: 2.0 4.0 -2.5568485260009766 -1.2784242630004883 -0.6392121315002441\n",
      "\tgrad: 3.0 6.0 2.578036308288574 0.8593454360961914 0.28644847869873047\n",
      "Epoch: 18 0.020513182505965233\n",
      "\tgrad: 1.0 2.0 0.10251188278198242 0.10251188278198242 0.10251188278198242\n",
      "\tgrad: 2.0 4.0 -2.5257606506347656 -1.2628803253173828 -0.6314401626586914\n",
      "\tgrad: 3.0 6.0 2.5334815979003906 0.8444938659667969 0.2814979553222656\n",
      "Epoch: 19 0.019810274243354797\n",
      "\tgrad: 1.0 2.0 0.1115732192993164 0.1115732192993164 0.1115732192993164\n",
      "\tgrad: 2.0 4.0 -2.4957752227783203 -1.2478876113891602 -0.6239438056945801\n",
      "\tgrad: 3.0 6.0 2.490780830383301 0.8302602767944336 0.27675342559814453\n",
      "Epoch: 20 0.019148115068674088\n",
      "\tgrad: 1.0 2.0 0.12027454376220703 0.12027454376220703 0.12027454376220703\n",
      "\tgrad: 2.0 4.0 -2.4669342041015625 -1.2334671020507812 -0.6167335510253906\n",
      "\tgrad: 3.0 6.0 2.4496335983276367 0.8165445327758789 0.27218151092529297\n",
      "Epoch: 21 0.018520694226026535\n",
      "\tgrad: 1.0 2.0 0.12863397598266602 0.12863397598266602 0.12863397598266602\n",
      "\tgrad: 2.0 4.0 -2.4391613006591797 -1.2195806503295898 -0.6097903251647949\n",
      "\tgrad: 3.0 6.0 2.4100828170776367 0.8033609390258789 0.26778697967529297\n",
      "Epoch: 22 0.017927465960383415\n",
      "\tgrad: 1.0 2.0 0.13666200637817383 0.13666200637817383 0.13666200637817383\n",
      "\tgrad: 2.0 4.0 -2.4124298095703125 -1.2062149047851562 -0.6031074523925781\n",
      "\tgrad: 3.0 6.0 2.3719911575317383 0.7906637191772461 0.26355457305908203\n",
      "Epoch: 23 0.01736525259912014\n",
      "\tgrad: 1.0 2.0 0.14437294006347656 0.14437294006347656 0.14437294006347656\n",
      "\tgrad: 2.0 4.0 -2.386688232421875 -1.1933441162109375 -0.5966720581054688\n",
      "\tgrad: 3.0 6.0 2.335367202758789 0.7784557342529297 0.25948524475097656\n",
      "Epoch: 24 0.016833148896694183\n",
      "\tgrad: 1.0 2.0 0.1517786979675293 0.1517786979675293 0.1517786979675293\n",
      "\tgrad: 2.0 4.0 -2.3619022369384766 -1.1809511184692383 -0.5904755592346191\n",
      "\tgrad: 3.0 6.0 2.30013370513916 0.7667112350463867 0.2555704116821289\n",
      "Epoch: 25 0.01632905937731266\n",
      "\tgrad: 1.0 2.0 0.1588902473449707 0.1588902473449707 0.1588902473449707\n",
      "\tgrad: 2.0 4.0 -2.338043212890625 -1.1690216064453125 -0.5845108032226562\n",
      "\tgrad: 3.0 6.0 2.2661962509155273 0.7553987503051758 0.2517995834350586\n",
      "Epoch: 26 0.01585075818002224\n",
      "\tgrad: 1.0 2.0 0.16572046279907227 0.16572046279907227 0.16572046279907227\n",
      "\tgrad: 2.0 4.0 -2.3150596618652344 -1.1575298309326172 -0.5787649154663086\n",
      "\tgrad: 3.0 6.0 2.233572006225586 0.7445240020751953 0.24817466735839844\n",
      "Epoch: 27 0.015397666022181511\n",
      "\tgrad: 1.0 2.0 0.17227888107299805 0.17227888107299805 0.17227888107299805\n",
      "\tgrad: 2.0 4.0 -2.2929306030273438 -1.1464653015136719 -0.5732326507568359\n",
      "\tgrad: 3.0 6.0 2.202157974243164 0.7340526580810547 0.24468421936035156\n",
      "Epoch: 28 0.014967591501772404\n",
      "\tgrad: 1.0 2.0 0.17857694625854492 0.17857694625854492 0.17857694625854492\n",
      "\tgrad: 2.0 4.0 -2.271617889404297 -1.1358089447021484 -0.5679044723510742\n",
      "\tgrad: 3.0 6.0 2.171945571899414 0.7239818572998047 0.24132728576660156\n",
      "Epoch: 29 0.014559715054929256\n",
      "\tgrad: 1.0 2.0 0.18462371826171875 0.18462371826171875 0.18462371826171875\n",
      "\tgrad: 2.0 4.0 -2.2510948181152344 -1.1255474090576172 -0.5627737045288086\n",
      "\tgrad: 3.0 6.0 2.142857551574707 0.7142858505249023 0.23809528350830078\n",
      "Epoch: 30 0.014172340743243694\n",
      "\tgrad: 1.0 2.0 0.1904296875 0.1904296875 0.1904296875\n",
      "\tgrad: 2.0 4.0 -2.231321334838867 -1.1156606674194336 -0.5578303337097168\n",
      "\tgrad: 3.0 6.0 2.1148509979248047 0.7049503326416016 0.2349834442138672\n",
      "Epoch: 31 0.013804304413497448\n",
      "\tgrad: 1.0 2.0 0.19600486755371094 0.19600486755371094 0.19600486755371094\n",
      "\tgrad: 2.0 4.0 -2.2122726440429688 -1.1061363220214844 -0.5530681610107422\n",
      "\tgrad: 3.0 6.0 2.087925910949707 0.6959753036499023 0.23199176788330078\n",
      "Epoch: 32 0.013455045409500599\n",
      "\tgrad: 1.0 2.0 0.2013559341430664 0.2013559341430664 0.2013559341430664\n",
      "\tgrad: 2.0 4.0 -2.193929672241211 -1.0969648361206055 -0.5484824180603027\n",
      "\tgrad: 3.0 6.0 2.061979293823242 0.6873264312744141 0.2291088104248047\n",
      "Epoch: 33 0.013122711330652237\n",
      "\tgrad: 1.0 2.0 0.20649433135986328 0.20649433135986328 0.20649433135986328\n",
      "\tgrad: 2.0 4.0 -2.176250457763672 -1.088125228881836 -0.544062614440918\n",
      "\tgrad: 3.0 6.0 2.037019729614258 0.6790065765380859 0.2263355255126953\n",
      "Epoch: 34 0.01280694268643856\n",
      "\tgrad: 1.0 2.0 0.21142578125 0.21142578125 0.21142578125\n",
      "\tgrad: 2.0 4.0 -2.1592159271240234 -1.0796079635620117 -0.5398039817810059\n",
      "\tgrad: 3.0 6.0 2.0130043029785156 0.6710014343261719 0.22366714477539062\n",
      "Epoch: 35 0.012506747618317604\n",
      "\tgrad: 1.0 2.0 0.21615982055664062 0.21615982055664062 0.21615982055664062\n",
      "\tgrad: 2.0 4.0 -2.142810821533203 -1.0714054107666016 -0.5357027053833008\n",
      "\tgrad: 3.0 6.0 1.9898557662963867 0.6632852554321289 0.22109508514404297\n",
      "Epoch: 36 0.012220758944749832\n",
      "\tgrad: 1.0 2.0 0.2207036018371582 0.2207036018371582 0.2207036018371582\n",
      "\tgrad: 2.0 4.0 -2.1269912719726562 -1.0634956359863281 -0.5317478179931641\n",
      "\tgrad: 3.0 6.0 1.967599868774414 0.6558666229248047 0.21862220764160156\n",
      "Epoch: 37 0.01194891706109047\n",
      "\tgrad: 1.0 2.0 0.22506427764892578 0.22506427764892578 0.22506427764892578\n",
      "\tgrad: 2.0 4.0 -2.1117515563964844 -1.0558757781982422 -0.5279378890991211\n",
      "\tgrad: 3.0 6.0 1.9461593627929688 0.6487197875976562 0.21623992919921875\n",
      "Epoch: 38 0.011689926497638226\n",
      "\tgrad: 1.0 2.0 0.2292490005493164 0.2292490005493164 0.2292490005493164\n",
      "\tgrad: 2.0 4.0 -2.0970611572265625 -1.0485305786132812 -0.5242652893066406\n",
      "\tgrad: 3.0 6.0 1.9255084991455078 0.6418361663818359 0.2139453887939453\n",
      "Epoch: 39 0.01144315768033266\n",
      "\tgrad: 1.0 2.0 0.23326539993286133 0.23326539993286133 0.23326539993286133\n",
      "\tgrad: 2.0 4.0 -2.082897186279297 -1.0414485931396484 -0.5207242965698242\n",
      "\tgrad: 3.0 6.0 1.9056644439697266 0.6352214813232422 0.21174049377441406\n",
      "Epoch: 40 0.011208509095013142\n",
      "\tgrad: 1.0 2.0 0.23711872100830078 0.23711872100830078 0.23711872100830078\n",
      "\tgrad: 2.0 4.0 -2.0692520141601562 -1.0346260070800781 -0.5173130035400391\n",
      "\tgrad: 3.0 6.0 1.8864898681640625 0.6288299560546875 0.2096099853515625\n",
      "Epoch: 41 0.0109840864315629\n",
      "\tgrad: 1.0 2.0 0.24081659317016602 0.24081659317016602 0.24081659317016602\n",
      "\tgrad: 2.0 4.0 -2.0560836791992188 -1.0280418395996094 -0.5140209197998047\n",
      "\tgrad: 3.0 6.0 1.8680963516235352 0.6226987838745117 0.2075662612915039\n",
      "Epoch: 42 0.010770938359200954\n",
      "\tgrad: 1.0 2.0 0.24436283111572266 0.24436283111572266 0.24436283111572266\n",
      "\tgrad: 2.0 4.0 -2.0433998107910156 -1.0216999053955078 -0.5108499526977539\n",
      "\tgrad: 3.0 6.0 1.850320816040039 0.6167736053466797 0.20559120178222656\n",
      "Epoch: 43 0.010566935874521732\n",
      "\tgrad: 1.0 2.0 0.24776697158813477 0.24776697158813477 0.24776697158813477\n",
      "\tgrad: 2.0 4.0 -2.0311546325683594 -1.0155773162841797 -0.5077886581420898\n",
      "\tgrad: 3.0 6.0 1.8332405090332031 0.6110801696777344 0.20369338989257812\n",
      "Epoch: 44 0.010372749529778957\n",
      "\tgrad: 1.0 2.0 0.25103092193603516 0.25103092193603516 0.25103092193603516\n",
      "\tgrad: 2.0 4.0 -2.0193519592285156 -1.0096759796142578 -0.5048379898071289\n",
      "\tgrad: 3.0 6.0 1.816786766052246 0.605595588684082 0.20186519622802734\n",
      "Epoch: 45 0.010187389329075813\n",
      "\tgrad: 1.0 2.0 0.2541618347167969 0.2541618347167969 0.2541618347167969\n",
      "\tgrad: 2.0 4.0 -2.0079689025878906 -1.0039844512939453 -0.5019922256469727\n",
      "\tgrad: 3.0 6.0 1.8009252548217773 0.6003084182739258 0.2001028060913086\n",
      "Epoch: 46 0.010010283440351486\n",
      "\tgrad: 1.0 2.0 0.25716400146484375 0.25716400146484375 0.25716400146484375\n",
      "\tgrad: 2.0 4.0 -1.9969863891601562 -0.9984931945800781 -0.49924659729003906\n",
      "\tgrad: 3.0 6.0 1.785630226135254 0.595210075378418 0.19840335845947266\n",
      "Epoch: 47 0.00984097272157669\n",
      "\tgrad: 1.0 2.0 0.2600440979003906 0.2600440979003906 0.2600440979003906\n",
      "\tgrad: 2.0 4.0 -1.9863853454589844 -0.9931926727294922 -0.4965963363647461\n",
      "\tgrad: 3.0 6.0 1.7709360122680664 0.5903120040893555 0.19677066802978516\n",
      "Epoch: 48 0.009679674170911312\n",
      "\tgrad: 1.0 2.0 0.2628040313720703 0.2628040313720703 0.2628040313720703\n",
      "\tgrad: 2.0 4.0 -1.976165771484375 -0.9880828857421875 -0.49404144287109375\n",
      "\tgrad: 3.0 6.0 1.7567567825317383 0.5855855941772461 0.19519519805908203\n",
      "Epoch: 49 0.009525291621685028\n",
      "\tgrad: 1.0 2.0 0.26545143127441406 0.26545143127441406 0.26545143127441406\n",
      "\tgrad: 2.0 4.0 -1.9663009643554688 -0.9831504821777344 -0.4915752410888672\n",
      "\tgrad: 3.0 6.0 1.7430925369262695 0.5810308456420898 0.19367694854736328\n",
      "Epoch: 50 0.00937769003212452\n",
      "\tgrad: 1.0 2.0 0.2679886817932129 0.2679886817932129 0.2679886817932129\n",
      "\tgrad: 2.0 4.0 -1.9567756652832031 -0.9783878326416016 -0.4891939163208008\n",
      "\tgrad: 3.0 6.0 1.7299346923828125 0.5766448974609375 0.1922149658203125\n",
      "Epoch: 51 0.009236648678779602\n",
      "\tgrad: 1.0 2.0 0.27042055130004883 0.27042055130004883 0.27042055130004883\n",
      "\tgrad: 2.0 4.0 -1.9475860595703125 -0.9737930297851562 -0.4868965148925781\n",
      "\tgrad: 3.0 6.0 1.717240333557129 0.572413444519043 0.19080448150634766\n",
      "Epoch: 52 0.00910158734768629\n",
      "\tgrad: 1.0 2.0 0.2727518081665039 0.2727518081665039 0.2727518081665039\n",
      "\tgrad: 2.0 4.0 -1.9387092590332031 -0.9693546295166016 -0.4846773147583008\n",
      "\tgrad: 3.0 6.0 1.705026626586914 0.5683422088623047 0.18944740295410156\n",
      "Epoch: 53 0.00897257961332798\n",
      "\tgrad: 1.0 2.0 0.27498531341552734 0.27498531341552734 0.27498531341552734\n",
      "\tgrad: 2.0 4.0 -1.9301414489746094 -0.9650707244873047 -0.48253536224365234\n",
      "\tgrad: 3.0 6.0 1.6932334899902344 0.5644111633300781 0.18813705444335938\n",
      "Epoch: 54 0.008848887868225574\n",
      "\tgrad: 1.0 2.0 0.27712535858154297 0.27712535858154297 0.27712535858154297\n",
      "\tgrad: 2.0 4.0 -1.9218635559082031 -0.9609317779541016 -0.4804658889770508\n",
      "\tgrad: 3.0 6.0 1.6818780899047852 0.5606260299682617 0.1868753433227539\n",
      "Epoch: 55 0.008730598725378513\n",
      "\tgrad: 1.0 2.0 0.2791757583618164 0.2791757583618164 0.2791757583618164\n",
      "\tgrad: 2.0 4.0 -1.9138717651367188 -0.9569358825683594 -0.4784679412841797\n",
      "\tgrad: 3.0 6.0 1.6709346771240234 0.5569782257080078 0.18565940856933594\n",
      "Epoch: 56 0.00861735362559557\n",
      "\tgrad: 1.0 2.0 0.2811393737792969 0.2811393737792969 0.2811393737792969\n",
      "\tgrad: 2.0 4.0 -1.9061508178710938 -0.9530754089355469 -0.47653770446777344\n",
      "\tgrad: 3.0 6.0 1.6603689193725586 0.5534563064575195 0.18448543548583984\n",
      "Epoch: 57 0.008508718572556973\n",
      "\tgrad: 1.0 2.0 0.28302001953125 0.28302001953125 0.28302001953125\n",
      "\tgrad: 2.0 4.0 -1.8986892700195312 -0.9493446350097656 -0.4746723175048828\n",
      "\tgrad: 3.0 6.0 1.6501893997192383 0.5500631332397461 0.18335437774658203\n",
      "Epoch: 58 0.008404706604778767\n",
      "\tgrad: 1.0 2.0 0.284820556640625 0.284820556640625 0.284820556640625\n",
      "\tgrad: 2.0 4.0 -1.8914775848388672 -0.9457387924194336 -0.4728693962097168\n",
      "\tgrad: 3.0 6.0 1.6403875350952148 0.5467958450317383 0.1822652816772461\n",
      "Epoch: 59 0.008305158466100693\n",
      "\tgrad: 1.0 2.0 0.2865438461303711 0.2865438461303711 0.2865438461303711\n",
      "\tgrad: 2.0 4.0 -1.8845138549804688 -0.9422569274902344 -0.4711284637451172\n",
      "\tgrad: 3.0 6.0 1.630894660949707 0.5436315536499023 0.18121051788330078\n",
      "Epoch: 60 0.00820931326597929\n",
      "\tgrad: 1.0 2.0 0.2881946563720703 0.2881946563720703 0.2881946563720703\n",
      "\tgrad: 2.0 4.0 -1.8777713775634766 -0.9388856887817383 -0.46944284439086914\n",
      "\tgrad: 3.0 6.0 1.621779441833496 0.540593147277832 0.18019771575927734\n",
      "Epoch: 61 0.008117804303765297\n",
      "\tgrad: 1.0 2.0 0.28977346420288086 0.28977346420288086 0.28977346420288086\n",
      "\tgrad: 2.0 4.0 -1.8712615966796875 -0.9356307983398438 -0.4678153991699219\n",
      "\tgrad: 3.0 6.0 1.6129646301269531 0.5376548767089844 0.17921829223632812\n",
      "Epoch: 62 0.008029798977077007\n",
      "\tgrad: 1.0 2.0 0.29128456115722656 0.29128456115722656 0.29128456115722656\n",
      "\tgrad: 2.0 4.0 -1.8649616241455078 -0.9324808120727539 -0.46624040603637695\n",
      "\tgrad: 3.0 6.0 1.6044673919677734 0.5348224639892578 0.17827415466308594\n",
      "Epoch: 63 0.007945418357849121\n",
      "\tgrad: 1.0 2.0 0.29272985458374023 0.29272985458374023 0.29272985458374023\n",
      "\tgrad: 2.0 4.0 -1.8588676452636719 -0.9294338226318359 -0.46471691131591797\n",
      "\tgrad: 3.0 6.0 1.5962448120117188 0.5320816040039062 0.17736053466796875\n",
      "Epoch: 64 0.007864190265536308\n",
      "\tgrad: 1.0 2.0 0.2941126823425293 0.2941126823425293 0.2941126823425293\n",
      "\tgrad: 2.0 4.0 -1.8529701232910156 -0.9264850616455078 -0.4632425308227539\n",
      "\tgrad: 3.0 6.0 1.5883655548095703 0.5294551849365234 0.1764850616455078\n",
      "Epoch: 65 0.007786744274199009\n",
      "\tgrad: 1.0 2.0 0.29543399810791016 0.29543399810791016 0.29543399810791016\n",
      "\tgrad: 2.0 4.0 -1.8472747802734375 -0.9236373901367188 -0.4618186950683594\n",
      "\tgrad: 3.0 6.0 1.5806922912597656 0.5268974304199219 0.17563247680664062\n",
      "Epoch: 66 0.007711691781878471\n",
      "\tgrad: 1.0 2.0 0.29669761657714844 0.29669761657714844 0.29669761657714844\n",
      "\tgrad: 2.0 4.0 -1.841745376586914 -0.920872688293457 -0.4604363441467285\n",
      "\tgrad: 3.0 6.0 1.5733451843261719 0.5244483947753906 0.17481613159179688\n",
      "Epoch: 67 0.007640169933438301\n",
      "\tgrad: 1.0 2.0 0.29790449142456055 0.29790449142456055 0.29790449142456055\n",
      "\tgrad: 2.0 4.0 -1.8364067077636719 -0.9182033538818359 -0.45910167694091797\n",
      "\tgrad: 3.0 6.0 1.5662040710449219 0.5220680236816406 0.17402267456054688\n",
      "Epoch: 68 0.007570972666144371\n",
      "\tgrad: 1.0 2.0 0.2990589141845703 0.2990589141845703 0.2990589141845703\n",
      "\tgrad: 2.0 4.0 -1.8312263488769531 -0.9156131744384766 -0.4578065872192383\n",
      "\tgrad: 3.0 6.0 1.5593376159667969 0.5197792053222656 0.17325973510742188\n",
      "Epoch: 69 0.007504733745008707\n",
      "\tgrad: 1.0 2.0 0.30016040802001953 0.30016040802001953 0.30016040802001953\n",
      "\tgrad: 2.0 4.0 -1.8262138366699219 -0.9131069183349609 -0.45655345916748047\n",
      "\tgrad: 3.0 6.0 1.552694320678711 0.5175647735595703 0.17252159118652344\n",
      "Epoch: 70 0.007440924644470215\n",
      "\tgrad: 1.0 2.0 0.30121278762817383 0.30121278762817383 0.30121278762817383\n",
      "\tgrad: 2.0 4.0 -1.8213577270507812 -0.9106788635253906 -0.4553394317626953\n",
      "\tgrad: 3.0 6.0 1.5462827682495117 0.5154275894165039 0.17180919647216797\n",
      "Epoch: 71 0.007379599846899509\n",
      "\tgrad: 1.0 2.0 0.3022174835205078 0.3022174835205078 0.3022174835205078\n",
      "\tgrad: 2.0 4.0 -1.8166522979736328 -0.9083261489868164 -0.4541630744934082\n",
      "\tgrad: 3.0 6.0 1.5400772094726562 0.5133590698242188 0.17111968994140625\n",
      "Epoch: 72 0.007320486940443516\n",
      "\tgrad: 1.0 2.0 0.3031759262084961 0.3031759262084961 0.3031759262084961\n",
      "\tgrad: 2.0 4.0 -1.8120880126953125 -0.9060440063476562 -0.4530220031738281\n",
      "\tgrad: 3.0 6.0 1.5340948104858398 0.5113649368286133 0.1704549789428711\n",
      "Epoch: 73 0.007263725157827139\n",
      "\tgrad: 1.0 2.0 0.3040900230407715 0.3040900230407715 0.3040900230407715\n",
      "\tgrad: 2.0 4.0 -1.8076667785644531 -0.9038333892822266 -0.4519166946411133\n",
      "\tgrad: 3.0 6.0 1.5283098220825195 0.5094366073608398 0.16981220245361328\n",
      "Epoch: 74 0.007209045812487602\n",
      "\tgrad: 1.0 2.0 0.304962158203125 0.304962158203125 0.304962158203125\n",
      "\tgrad: 2.0 4.0 -1.8033790588378906 -0.9016895294189453 -0.45084476470947266\n",
      "\tgrad: 3.0 6.0 1.5227222442626953 0.5075740814208984 0.1691913604736328\n",
      "Epoch: 75 0.007156429346650839\n",
      "\tgrad: 1.0 2.0 0.30579280853271484 0.30579280853271484 0.30579280853271484\n",
      "\tgrad: 2.0 4.0 -1.7992210388183594 -0.8996105194091797 -0.44980525970458984\n",
      "\tgrad: 3.0 6.0 1.5172977447509766 0.5057659149169922 0.16858863830566406\n",
      "Epoch: 76 0.007105532102286816\n",
      "\tgrad: 1.0 2.0 0.30658483505249023 0.30658483505249023 0.30658483505249023\n",
      "\tgrad: 2.0 4.0 -1.7951812744140625 -0.8975906372070312 -0.4487953186035156\n",
      "\tgrad: 3.0 6.0 1.5120878219604492 0.5040292739868164 0.16800975799560547\n",
      "Epoch: 77 0.00705681974068284\n",
      "\tgrad: 1.0 2.0 0.3073387145996094 0.3073387145996094 0.3073387145996094\n",
      "\tgrad: 2.0 4.0 -1.791269302368164 -0.895634651184082 -0.447817325592041\n",
      "\tgrad: 3.0 6.0 1.5070152282714844 0.5023384094238281 0.16744613647460938\n",
      "Epoch: 78 0.007009552326053381\n",
      "\tgrad: 1.0 2.0 0.3080568313598633 0.3080568313598633 0.3080568313598633\n",
      "\tgrad: 2.0 4.0 -1.7874603271484375 -0.8937301635742188 -0.4468650817871094\n",
      "\tgrad: 3.0 6.0 1.502131462097168 0.5007104873657227 0.16690349578857422\n",
      "Epoch: 79 0.006964194122701883\n",
      "\tgrad: 1.0 2.0 0.30873966217041016 0.30873966217041016 0.30873966217041016\n",
      "\tgrad: 2.0 4.0 -1.7837696075439453 -0.8918848037719727 -0.44594240188598633\n",
      "\tgrad: 3.0 6.0 1.4973936080932617 0.4991312026977539 0.16637706756591797\n",
      "Epoch: 80 0.006920332089066505\n",
      "\tgrad: 1.0 2.0 0.309389591217041 0.309389591217041 0.309389591217041\n",
      "\tgrad: 2.0 4.0 -1.780181884765625 -0.8900909423828125 -0.44504547119140625\n",
      "\tgrad: 3.0 6.0 1.492818832397461 0.4976062774658203 0.16586875915527344\n",
      "Epoch: 81 0.006878111511468887\n",
      "\tgrad: 1.0 2.0 0.31000614166259766 0.31000614166259766 0.31000614166259766\n",
      "\tgrad: 2.0 4.0 -1.7766971588134766 -0.8883485794067383 -0.44417428970336914\n",
      "\tgrad: 3.0 6.0 1.4883899688720703 0.49612998962402344 0.1653766632080078\n",
      "Epoch: 82 0.006837360095232725\n",
      "\tgrad: 1.0 2.0 0.3105926513671875 0.3105926513671875 0.3105926513671875\n",
      "\tgrad: 2.0 4.0 -1.7733135223388672 -0.8866567611694336 -0.4433283805847168\n",
      "\tgrad: 3.0 6.0 1.4840812683105469 0.4946937561035156 0.16489791870117188\n",
      "Epoch: 83 0.006797831039875746\n",
      "\tgrad: 1.0 2.0 0.31114959716796875 0.31114959716796875 0.31114959716796875\n",
      "\tgrad: 2.0 4.0 -1.7700138092041016 -0.8850069046020508 -0.4425034523010254\n",
      "\tgrad: 3.0 6.0 1.4799528121948242 0.4933176040649414 0.16443920135498047\n",
      "Epoch: 84 0.006760062649846077\n",
      "\tgrad: 1.0 2.0 0.3116769790649414 0.3116769790649414 0.3116769790649414\n",
      "\tgrad: 2.0 4.0 -1.7668170928955078 -0.8834085464477539 -0.44170427322387695\n",
      "\tgrad: 3.0 6.0 1.4759016036987305 0.49196720123291016 0.16398906707763672\n",
      "Epoch: 85 0.006723103579133749\n",
      "\tgrad: 1.0 2.0 0.3121776580810547 0.3121776580810547 0.3121776580810547\n",
      "\tgrad: 2.0 4.0 -1.7636966705322266 -0.8818483352661133 -0.44092416763305664\n",
      "\tgrad: 3.0 6.0 1.4720134735107422 0.49067115783691406 0.1635570526123047\n",
      "Epoch: 86 0.00668772729113698\n",
      "\tgrad: 1.0 2.0 0.3126516342163086 0.3126516342163086 0.3126516342163086\n",
      "\tgrad: 2.0 4.0 -1.7606639862060547 -0.8803319931030273 -0.44016599655151367\n",
      "\tgrad: 3.0 6.0 1.4682197570800781 0.4894065856933594 0.16313552856445312\n",
      "Epoch: 87 0.006653300020843744\n",
      "\tgrad: 1.0 2.0 0.31310081481933594 0.31310081481933594 0.31310081481933594\n",
      "\tgrad: 2.0 4.0 -1.7577095031738281 -0.8788547515869141 -0.43942737579345703\n",
      "\tgrad: 3.0 6.0 1.4645805358886719 0.4881935119628906 0.16273117065429688\n",
      "Epoch: 88 0.0066203586757183075\n",
      "\tgrad: 1.0 2.0 0.3135242462158203 0.3135242462158203 0.3135242462158203\n",
      "\tgrad: 2.0 4.0 -1.754842758178711 -0.8774213790893555 -0.43871068954467773\n",
      "\tgrad: 3.0 6.0 1.4610099792480469 0.4870033264160156 0.16233444213867188\n",
      "Epoch: 89 0.0065881176851689816\n",
      "\tgrad: 1.0 2.0 0.31392478942871094 0.31392478942871094 0.31392478942871094\n",
      "\tgrad: 2.0 4.0 -1.7520370483398438 -0.8760185241699219 -0.43800926208496094\n",
      "\tgrad: 3.0 6.0 1.457585334777832 0.48586177825927734 0.16195392608642578\n",
      "Epoch: 90 0.0065572685562074184\n",
      "\tgrad: 1.0 2.0 0.314302921295166 0.314302921295166 0.314302921295166\n",
      "\tgrad: 2.0 4.0 -1.7493114471435547 -0.8746557235717773 -0.43732786178588867\n",
      "\tgrad: 3.0 6.0 1.4542293548583984 0.4847431182861328 0.16158103942871094\n",
      "Epoch: 91 0.0065271081402897835\n",
      "\tgrad: 1.0 2.0 0.31465959548950195 0.31465959548950195 0.31465959548950195\n",
      "\tgrad: 2.0 4.0 -1.7466468811035156 -0.8733234405517578 -0.4366617202758789\n",
      "\tgrad: 3.0 6.0 1.4509849548339844 0.4836616516113281 0.16122055053710938\n",
      "Epoch: 92 0.00649801641702652\n",
      "\tgrad: 1.0 2.0 0.31499528884887695 0.31499528884887695 0.31499528884887695\n",
      "\tgrad: 2.0 4.0 -1.7440509796142578 -0.8720254898071289 -0.43601274490356445\n",
      "\tgrad: 3.0 6.0 1.4478435516357422 0.48261451721191406 0.1608715057373047\n",
      "Epoch: 93 0.0064699104987084866\n",
      "\tgrad: 1.0 2.0 0.3153109550476074 0.3153109550476074 0.3153109550476074\n",
      "\tgrad: 2.0 4.0 -1.7415199279785156 -0.8707599639892578 -0.4353799819946289\n",
      "\tgrad: 3.0 6.0 1.4447879791259766 0.4815959930419922 0.16053199768066406\n",
      "Epoch: 94 0.006442630663514137\n",
      "\tgrad: 1.0 2.0 0.31560707092285156 0.31560707092285156 0.31560707092285156\n",
      "\tgrad: 2.0 4.0 -1.7390518188476562 -0.8695259094238281 -0.43476295471191406\n",
      "\tgrad: 3.0 6.0 1.4418182373046875 0.4806060791015625 0.1602020263671875\n",
      "Epoch: 95 0.006416172254830599\n",
      "\tgrad: 1.0 2.0 0.3158855438232422 0.3158855438232422 0.3158855438232422\n",
      "\tgrad: 2.0 4.0 -1.7366409301757812 -0.8683204650878906 -0.4341602325439453\n",
      "\tgrad: 3.0 6.0 1.4389429092407227 0.4796476364135742 0.1598825454711914\n",
      "Epoch: 96 0.006390606984496117\n",
      "\tgrad: 1.0 2.0 0.3161449432373047 0.3161449432373047 0.3161449432373047\n",
      "\tgrad: 2.0 4.0 -1.7342891693115234 -0.8671445846557617 -0.43357229232788086\n",
      "\tgrad: 3.0 6.0 1.436136245727539 0.4787120819091797 0.15957069396972656\n",
      "Epoch: 97 0.0063657015562057495\n",
      "\tgrad: 1.0 2.0 0.3163881301879883 0.3163881301879883 0.3163881301879883\n",
      "\tgrad: 2.0 4.0 -1.7319889068603516 -0.8659944534301758 -0.4329972267150879\n",
      "\tgrad: 3.0 6.0 1.4334239959716797 0.47780799865722656 0.1592693328857422\n",
      "Epoch: 98 0.0063416799530386925\n",
      "\tgrad: 1.0 2.0 0.31661415100097656 0.31661415100097656 0.31661415100097656\n",
      "\tgrad: 2.0 4.0 -1.7297439575195312 -0.8648719787597656 -0.4324359893798828\n",
      "\tgrad: 3.0 6.0 1.4307546615600586 0.47691822052001953 0.15897274017333984\n",
      "Epoch: 99 0.00631808303296566\n",
      "Predict(after training) 4 8.544171333312988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w1 = torch.Tensor([1.0])      # 初始权值\n",
    "w1.requires_grad = True       # 计算梯度，默认是不计算的\n",
    "w2 = torch.Tensor([1.0])\n",
    "w2.requires_grad = True\n",
    "b = torch.Tensor([1.0])\n",
    "b.requires_grad = True\n",
    "\n",
    "def forward(x):\n",
    "    return w1 * x**2 + w2 * x + b\n",
    "\n",
    "def loss(x,y):                 # 构建计算图\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y) **2\n",
    "\n",
    "print('Predict (befortraining)', 4, forward(4))\n",
    "\n",
    "for epoch in range(100):\n",
    "    l = loss(1, 2)             # 为了在for循环之前定义l,以便之后的输出，无实际意义\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        l = loss(x, y)\n",
    "        l.backward()\n",
    "        print('\\tgrad:', x, y, w1.grad.item(), w2.grad.item(), b.grad.item())\n",
    "        w1.data = w1.data - 0.01*w1.grad.data      # 注意这里的grad是一个tensor，所以要取他的data\n",
    "        w2.data = w2.data - 0.01 * w2.grad.data\n",
    "        b.data = b.data - 0.01 * b.grad.data\n",
    "        w1.grad.data.zero_()                      # 释放之前计算的梯度\n",
    "        w2.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    print('Epoch:', epoch, l.item())\n",
    "\n",
    "print('Predict(after training)', 4, forward(4).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
